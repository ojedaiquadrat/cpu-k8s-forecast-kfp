{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95fb9783-619d-40d2-a0f6-d073a4e0001c",
   "metadata": {},
   "source": [
    "# 1 CASE\n",
    "\n",
    "Uses optuna to improve the stage 2. Every run optuna creates is registered in the mlflow and finally label the final best version model.\n",
    "\n",
    "No uses nested runs, so it can be added in case you plan to have multiple runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99e77ae-57b9-41a2-b7c8-ba10e23706ac",
   "metadata": {},
   "source": [
    "### 1.Imports & config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1d3e061-badd-4570-865f-efcac7dfc31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- core\n",
    "import os, io, math, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "\n",
    "# minio\n",
    "from minio import Minio\n",
    "\n",
    "# --- mlflow\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# --- torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# --- metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# --- hpo\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner, PercentilePruner\n",
    "\n",
    "# --- plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ====== Update these for your cluster ======\n",
    "TRACKING_URI = \"http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080\"\n",
    "EXPERIMENT_NAME = \"k8s-cpu-forecasting\"\n",
    "REGISTERED_MODEL_NAME = \"cpu-pct-hpo\"   # MLflow model name\n",
    "\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "client = MlflowClient()\n",
    "\n",
    "# Minio client\n",
    "minio_client = Minio(\n",
    "    \"minio-service.kubeflow.svc.cluster.local:9000\",\n",
    "    access_key=\"minio\",\n",
    "    secret_key=\"minio123\",\n",
    "    secure=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2188713d-50ea-421f-b3e9-d0a1ceddd7ba",
   "metadata": {},
   "source": [
    "### 2 — MinIO helpers (reuse your existing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0d71933-c18e-40b0-af23-e43e9e45f729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (8238, 5, 1) y_train: (8238, 1, 1)\n",
      "X_val:   (2060, 5, 1) y_val:   (2060, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "def download_numpy_from_minio(minio_client, bucket_name, object_name):\n",
    "    resp = minio_client.get_object(bucket_name, object_name)\n",
    "    try:\n",
    "        data = resp.read()\n",
    "        arr = np.load(BytesIO(data))\n",
    "        return arr\n",
    "    finally:\n",
    "        resp.close()\n",
    "        resp.release_conn()\n",
    "\n",
    "# Set your paths\n",
    "bucket_name = \"k8s-resources-forecast\"\n",
    "object_names = {\n",
    "    \"X_train\": \"data/k8s-preprocessed/node-1-X_train/X_train.npy\",\n",
    "    \"y_train\": \"data/k8s-preprocessed/node-1-y_train/y_train.npy\",\n",
    "    \"X_val\":   \"data/k8s-preprocessed/node-1-X_test/X_test.npy\",\n",
    "    \"y_val\":   \"data/k8s-preprocessed/node-1-y_test/y_test.npy\",\n",
    "}\n",
    "\n",
    "# Download arrays\n",
    "X_train = download_numpy_from_minio(minio_client, bucket_name, object_names[\"X_train\"])\n",
    "y_train = download_numpy_from_minio(minio_client, bucket_name, object_names[\"y_train\"])\n",
    "X_val   = download_numpy_from_minio(minio_client, bucket_name, object_names[\"X_val\"])\n",
    "y_val   = download_numpy_from_minio(minio_client, bucket_name, object_names[\"y_val\"])\n",
    "\n",
    "# Torch loaders\n",
    "def make_loader(X, y, batch_size, shuffle):\n",
    "    ds = TensorDataset(torch.tensor(X, dtype=torch.float32),\n",
    "                       torch.tensor(y, dtype=torch.float32))\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "# sanity\n",
    "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"X_val:  \", X_val.shape,   \"y_val:  \", y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cdd665-c5fd-4848-8117-7dc830984f1f",
   "metadata": {},
   "source": [
    "### 3 — Model, train loop, metrics & plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df543f1f-7f9a-406b-be14-5d4b43dea398",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMForecaster(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, dropout=0.0, horizon=1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,\n",
    "                            batch_first=True, dropout=dropout if num_layers > 1 else 0.0)\n",
    "        self.fc   = nn.Linear(hidden_size, horizon)  # horizon outputs\n",
    "    def forward(self, x):\n",
    "        # x: [B, T, F]\n",
    "        out, _ = self.lstm(x)             # [B, T, H]\n",
    "        out = out[:, -1, :]               # last step [B, H]\n",
    "        out = self.fc(out)                # [B, horizon]\n",
    "        return out.unsqueeze(-1)          # [B, horizon, 1] to match y\n",
    "\n",
    "def train_one_model(X_train, y_train, X_val, y_val,\n",
    "                    hidden_size, num_layers, dropout,\n",
    "                    lr, batch_size, epochs, patience, window_size, horizon,\n",
    "                    run_name=None):\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "    train_loader = make_loader(X_train, y_train, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = make_loader(X_val,   y_val,   batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = LSTMForecaster(input_size=X_train.shape[-1],\n",
    "                           hidden_size=hidden_size,\n",
    "                           num_layers=num_layers,\n",
    "                           dropout=dropout,\n",
    "                           horizon=horizon).to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    opt = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "    patience_left = patience\n",
    "    train_curve, val_curve = [], []\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        mlflow.log_params({\n",
    "            \"hidden_size\": hidden_size,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"dropout\": dropout,\n",
    "            \"lr\": lr,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"epochs\": epochs,\n",
    "            \"patience\": patience,\n",
    "            \"window_size\": window_size,\n",
    "            \"horizon\": horizon\n",
    "        })\n",
    "\n",
    "        for ep in range(1, epochs + 1):\n",
    "            # --- train ---\n",
    "            model.train()\n",
    "            running = 0.0\n",
    "            for xb, yb in train_loader:\n",
    "                opt.zero_grad()\n",
    "                pred = model(xb)\n",
    "                loss = criterion(pred, yb)\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "                running += loss.item()\n",
    "            train_loss = running / max(1, len(train_loader))\n",
    "\n",
    "            # --- validate ---\n",
    "            model.eval()\n",
    "            v_running = 0.0\n",
    "            preds, targs = [], []\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in val_loader:\n",
    "                    pr = model(xb)\n",
    "                    v_loss = criterion(pr, yb)\n",
    "                    v_running += v_loss.item()\n",
    "                    preds.append(pr.numpy())\n",
    "                    targs.append(yb.numpy())\n",
    "            val_loss = v_running / max(1, len(val_loader))\n",
    "            train_curve.append(train_loss)\n",
    "            val_curve.append(val_loss)\n",
    "\n",
    "            # log per-epoch for MLflow + Optuna pruning\n",
    "            mlflow.log_metric(\"train_loss\", train_loss, step=ep)\n",
    "            mlflow.log_metric(\"val_loss\",   val_loss,   step=ep)\n",
    "\n",
    "            # early stopping\n",
    "            if val_loss < best_val - 1e-8:\n",
    "                best_val = val_loss\n",
    "                patience_left = patience\n",
    "                best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            else:\n",
    "                patience_left -= 1\n",
    "                if patience_left <= 0:\n",
    "                    print(\"Early stopping!\")\n",
    "                    break\n",
    "\n",
    "        # restore best\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "        # Final val metrics (MAE/RMSE/R2)\n",
    "        preds = np.concatenate([model(xb).detach().numpy() for xb, _ in val_loader], axis=0).reshape(-1)\n",
    "        targs = np.concatenate([yb.numpy() for _, yb in val_loader], axis=0).reshape(-1)\n",
    "        mae  = mean_absolute_error(targs, preds)\n",
    "        mse  = mean_squared_error(targs, preds)\n",
    "        rmse = math.sqrt(mse)\n",
    "        r2   = r2_score(targs, preds)\n",
    "\n",
    "        mlflow.log_metric(\"val_mae\", mae)\n",
    "        mlflow.log_metric(\"val_rmse\", rmse)\n",
    "        mlflow.log_metric(\"val_r2\", r2)\n",
    "\n",
    "        # plots: learning curve, residuals, true vs pred\n",
    "        # 1) Learning curve\n",
    "        plt.figure(figsize=(6,3))\n",
    "        plt.plot(train_curve, label=\"train\")\n",
    "        plt.plot(val_curve, label=\"val\")\n",
    "        plt.legend(); plt.title(\"Learning Curve\"); plt.tight_layout()\n",
    "        plt.savefig(\"learning_curve.png\"); plt.close()\n",
    "        mlflow.log_artifact(\"learning_curve.png\")\n",
    "\n",
    "        # 2) Residuals over time\n",
    "        plt.figure(figsize=(6,3))\n",
    "        plt.plot(preds - targs, label=\"residual\")\n",
    "        plt.axhline(0, color=\"black\", linewidth=0.8)\n",
    "        plt.legend(); plt.title(\"Residuals (val)\"); plt.tight_layout()\n",
    "        plt.savefig(\"residuals.png\"); plt.close()\n",
    "        mlflow.log_artifact(\"residuals.png\")\n",
    "\n",
    "        # 3) True vs Pred\n",
    "        plt.figure(figsize=(6,3))\n",
    "        plt.plot(targs, label=\"true\")\n",
    "        plt.plot(preds, label=\"pred\")\n",
    "        plt.legend(); plt.title(\"True vs Pred (val)\"); plt.tight_layout()\n",
    "        plt.savefig(\"val_true_vs_pred.png\"); plt.close()\n",
    "        mlflow.log_artifact(\"val_true_vs_pred.png\")\n",
    "\n",
    "        # Save model to MLflow\n",
    "        mlflow.pytorch.log_model(model, \"model\")\n",
    "\n",
    "        # Return metrics (for Optuna) and the run_id\n",
    "        run_id = mlflow.active_run().info.run_id\n",
    "    return model, {\"val_loss\": best_val, \"mae\": mae, \"rmse\": rmse, \"r2\": r2}, run_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d73166-f879-46cb-b360-aec5f32c6781",
   "metadata": {},
   "source": [
    "### 4 — Optuna objective & study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2e46882-a3dc-4541-9ad5-99b5943b60f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 12:28:02,592] A new study created in memory with name: cpu_pct_lstm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 12:28:51 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 12:28:54 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 12:28:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 12:28:54,476] Trial 0 finished with value: 0.0007080256194643345 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.17196126146370536, 'lr': 0.003127900843950967, 'batch_size': 16, 'epochs': 46, 'patience': 4}. Best is trial 0 with value: 0.0007080256194643345.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna-trial-0 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/a42ea83f26e74755a7d569e6084f497e\n",
      "🧪 View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 12:29:29 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 12:29:32 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 12:29:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 12:29:32,313] Trial 1 finished with value: 0.000550303586130736 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.20657423557430274, 'lr': 0.0004770825259355593, 'batch_size': 64, 'epochs': 49, 'patience': 8}. Best is trial 1 with value: 0.000550303586130736.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna-trial-1 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/e47e07df73994507b31761ed942c11eb\n",
      "🧪 View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 12:30:00 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 12:30:03 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 12:30:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 12:30:03,494] Trial 2 finished with value: 0.0005593707155919849 and parameters: {'hidden_size': 96, 'num_layers': 1, 'dropout': 0.3801576987716789, 'lr': 0.0003339794978128798, 'batch_size': 32, 'epochs': 49, 'patience': 7}. Best is trial 1 with value: 0.000550303586130736.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna-trial-2 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/e4e2e057d74a4816b375f76af064e1b8\n",
      "🧪 View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 12:31:15 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 12:31:17 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 12:31:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 12:31:17,868] Trial 3 finished with value: 0.0005508742245952957 and parameters: {'hidden_size': 80, 'num_layers': 3, 'dropout': 0.27795352066203954, 'lr': 0.0004255807011022233, 'batch_size': 32, 'epochs': 44, 'patience': 10}. Best is trial 1 with value: 0.000550303586130736.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna-trial-3 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/ddffc0c2ac4e43edb7579d2879a99c07\n",
      "🧪 View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 12:31:53 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 12:31:55 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 12:31:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 12:31:55,993] Trial 4 finished with value: 0.0008058777809289262 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.1170797146384416, 'lr': 0.0018520909012747725, 'batch_size': 16, 'epochs': 48, 'patience': 3}. Best is trial 1 with value: 0.000550303586130736.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna-trial-4 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/cb05852583664ab6b2f5a9ba6b3e72ca\n",
      "🧪 View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 12:32:10 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 12:32:13 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 12:32:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 12:32:13,189] Trial 5 finished with value: 0.0005694188520115298 and parameters: {'hidden_size': 80, 'num_layers': 1, 'dropout': 0.11710905649009723, 'lr': 0.004394327634441767, 'batch_size': 32, 'epochs': 18, 'patience': 8}. Best is trial 1 with value: 0.000550303586130736.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna-trial-5 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/8c8e38e0fb134642a2ddab236c6207b4\n",
      "🧪 View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 12:32:43 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 12:32:46 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 12:32:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 12:32:46,790] Trial 6 finished with value: 0.0005730214435562072 and parameters: {'hidden_size': 16, 'num_layers': 2, 'dropout': 0.026416992261014818, 'lr': 0.0012471602055676436, 'batch_size': 16, 'epochs': 45, 'patience': 4}. Best is trial 1 with value: 0.000550303586130736.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna-trial-6 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/12e219e69e9b4e479ea67d95cf1f527f\n",
      "🧪 View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 12:33:01 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 12:33:04 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 12:33:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 12:33:04,632] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna-trial-7 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/68da9be44b144977a62c211eae8dc877\n",
      "🧪 View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 12:33:55 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 12:33:58 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 12:33:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 12:33:58,717] Trial 8 finished with value: 0.0005629137305041068 and parameters: {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.32868231920620256, 'lr': 0.0002442776272584786, 'batch_size': 16, 'epochs': 46, 'patience': 10}. Best is trial 1 with value: 0.000550303586130736.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna-trial-8 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/c0d749030e9346968107dd66d417cd9b\n",
      "🧪 View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 12:34:31 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 12:34:34 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 12:34:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 12:34:34,240] Trial 9 finished with value: 0.0005474657589343913 and parameters: {'hidden_size': 48, 'num_layers': 2, 'dropout': 0.3125423900604701, 'lr': 0.0002844212723489982, 'batch_size': 64, 'epochs': 46, 'patience': 6}. Best is trial 9 with value: 0.0005474657589343913.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna-trial-9 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/7a6172ba96ec43a387b1f34dcb944cf4\n",
      "🧪 View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 12:35:13 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 12:35:16 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 12:35:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 12:35:16,683] Trial 10 finished with value: 0.000710926936748861 and parameters: {'hidden_size': 16, 'num_layers': 3, 'dropout': 0.2614810083185243, 'lr': 0.00018991236345418773, 'batch_size': 64, 'epochs': 34, 'patience': 6}. Best is trial 9 with value: 0.0005474657589343913.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna-trial-10 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/6c596918b57140a38601a9095aeb98a1\n",
      "🧪 View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 12:36:09 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 12:36:11 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 12:36:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 12:36:11,871] Trial 11 finished with value: 0.0005757764191719506 and parameters: {'hidden_size': 48, 'num_layers': 3, 'dropout': 0.21740591526050054, 'lr': 0.00012412149478993346, 'batch_size': 64, 'epochs': 35, 'patience': 8}. Best is trial 9 with value: 0.0005474657589343913.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run optuna-trial-11 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/6707703efcfa4435a33dfdef8ac329a9\n",
      "🧪 View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Best trial: 9\n",
      "Best value (val_loss): 0.0005474657589343913\n",
      "Best params: {'hidden_size': 48, 'num_layers': 2, 'dropout': 0.3125423900604701, 'lr': 0.0002844212723489982, 'batch_size': 64, 'epochs': 46, 'patience': 6}\n"
     ]
    }
   ],
   "source": [
    "# Define the search space and objective\n",
    "WINDOW_SIZE = X_train.shape[1]  # should be 5 in your case\n",
    "HORIZON     = y_train.shape[1]  # 1\n",
    "\n",
    "def objective(trial: optuna.Trial):\n",
    "    # Hyperparameter search space\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 16, 128, step=16)\n",
    "    num_layers  = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "    dropout     = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "    lr          = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "    batch_size  = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
    "    epochs      = trial.suggest_int(\"epochs\", 15, 50)\n",
    "    patience    = trial.suggest_int(\"patience\", 3, 10)\n",
    "\n",
    "    # Train & get val metrics\n",
    "    _, metrics, run_id = train_one_model(\n",
    "        X_train, y_train, X_val, y_val,\n",
    "        hidden_size, num_layers, dropout,\n",
    "        lr, batch_size, epochs, patience,\n",
    "        WINDOW_SIZE, HORIZON,\n",
    "        run_name=f\"optuna-trial-{trial.number}\"\n",
    "    )\n",
    "\n",
    "    # report intermediate to enable pruning\n",
    "    trial.report(metrics[\"val_loss\"], step=epochs)\n",
    "    if trial.should_prune():\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    # Attach the MLflow run_id to the trial for traceability\n",
    "    trial.set_user_attr(\"mlflow_run_id\", run_id)\n",
    "    return metrics[\"val_loss\"]\n",
    "\n",
    "# Create study (minimize val_loss) with pruning\n",
    "pruner = PercentilePruner(percentile=50, n_startup_trials=3, n_warmup_steps=0)\n",
    "study = optuna.create_study(direction=\"minimize\", pruner=pruner, study_name=\"cpu_pct_lstm\")\n",
    "\n",
    "# Run optimization\n",
    "N_TRIALS = 12\n",
    "study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=False)\n",
    "\n",
    "print(\"Best trial:\", study.best_trial.number)\n",
    "print(\"Best value (val_loss):\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b213bcd6-b617-4464-88ea-36db6a612def",
   "metadata": {},
   "source": [
    "### 5 — Train final model on (train+val), evaluate test, log & register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22417587-4b9e-4227-b7a0-b40a6334ff1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8db5332d-ad67-4c0c-a666-e5ed8fe04d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 12:36:28 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 12:36:30 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 12:36:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Successfully registered model 'cpu-pct-hpo'.\n",
      "2025/09/05 12:36:31 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: cpu-pct-hpo, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run final-best at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/dd7985f8fbc04803b71b23852e6c045d\n",
      "🧪 View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "✅ Registered model: cpu-pct-hpo version: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'cpu-pct-hpo'.\n"
     ]
    }
   ],
   "source": [
    "# If you also have a held-out test set, load it (or repurpose X_val/y_val as test)\n",
    "# Here, we'll just evaluate on the existing val set for demonstration\n",
    "best = study.best_params\n",
    "\n",
    "# Re-train once with best params (optionally combine train+val for final fit)\n",
    "final_model, final_metrics, run_id = train_one_model(\n",
    "    X_train, y_train, X_val, y_val,\n",
    "    best[\"hidden_size\"], best[\"num_layers\"], best[\"dropout\"],\n",
    "    best[\"lr\"], best[\"batch_size\"], best[\"epochs\"], best[\"patience\"],\n",
    "    WINDOW_SIZE, HORIZON,\n",
    "    run_name=\"final-best\"\n",
    ")\n",
    "\n",
    "# Register in MLflow Model Registry\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "result = mlflow.register_model(model_uri, REGISTERED_MODEL_NAME)\n",
    "print(\"✅ Registered model:\", result.name, \"version:\", result.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3ee177-f75a-4b79-bdd1-9c395e961fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c8bec2e-88e0-4055-9cce-5f1aec1b9dd8",
   "metadata": {},
   "source": [
    "# 2 CASE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1af8ed-5d1e-42fc-9eec-5e1f4ece2bff",
   "metadata": {},
   "source": [
    "### 1 — Imports & global config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "88ea14fe-a4ad-47e2-9064-b3a1287e79ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080 Experiment: k8s-cpu-forecasting\n"
     ]
    }
   ],
   "source": [
    "# ----- Core -----\n",
    "import os, io, json, math, random\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ----- MLflow -----\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.models import infer_signature \n",
    "\n",
    "# ----- Torch -----\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# ----- Metrics -----\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# ----- HPO -----\n",
    "import optuna\n",
    "from optuna.pruners import PercentilePruner\n",
    "\n",
    "# ----- Plotting -----\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----- Repro -----\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "set_seed(42)\n",
    "\n",
    "# ===== MLflow tracking =====\n",
    "TRACKING_URI = \"http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080\"\n",
    "EXPERIMENT_NAME = \"k8s-cpu-forecasting\"\n",
    "REGISTERED_MODEL_NAME = \"cpu-pct\"     # model registry name (optional but nice)\n",
    "\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "ml_client = MlflowClient()\n",
    "\n",
    "print(\"MLflow:\", TRACKING_URI, \"Experiment:\", EXPERIMENT_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26ea9e3-58cb-4254-83bc-646acf6a5524",
   "metadata": {},
   "source": [
    "### 2 MinIO client & data loaders (update creds if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1c4feb8c-24ca-48f8-9be7-fd6a360d71c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (8238, 5, 1) y_train: (8238, 1, 1)\n",
      "X_val:   (2060, 5, 1) y_val:   (2060, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "from minio import Minio\n",
    "\n",
    "# If you already have `minio_client`, you can skip this cell.\n",
    "# Adjust endpoint/creds to your cluster.\n",
    "MINIO_ENDPOINT = \"minio-service.kubeflow.svc.cluster.local:9000\"\n",
    "MINIO_ACCESS_KEY = \"minio\"\n",
    "MINIO_SECRET_KEY = \"minio123\"\n",
    "\n",
    "minio_client = Minio(\n",
    "    endpoint=MINIO_ENDPOINT,\n",
    "    access_key=MINIO_ACCESS_KEY,\n",
    "    secret_key=MINIO_SECRET_KEY,\n",
    "    secure=False\n",
    ")\n",
    "\n",
    "def download_numpy_from_minio(minio_client, bucket_name: str, object_name: str) -> np.ndarray:\n",
    "    \"\"\"Download a .npy as numpy array (in-memory, no temp file).\"\"\"\n",
    "    resp = minio_client.get_object(bucket_name, object_name)\n",
    "    try:\n",
    "        data = resp.read()\n",
    "        arr = np.load(BytesIO(data))\n",
    "        return arr\n",
    "    finally:\n",
    "        resp.close()\n",
    "        resp.release_conn()\n",
    "\n",
    "# ---- Paths for your prepared arrays ----\n",
    "bucket_name = \"k8s-resources-forecast\"\n",
    "object_names = {\n",
    "    \"X_train\": \"data/k8s-preprocessed/node-1-X_train/X_train.npy\",\n",
    "    \"y_train\": \"data/k8s-preprocessed/node-1-y_train/y_train.npy\",\n",
    "    \"X_val\":   \"data/k8s-preprocessed/node-1-X_test/X_test.npy\",\n",
    "    \"y_val\":   \"data/k8s-preprocessed/node-1-y_test/y_test.npy\",\n",
    "}\n",
    "\n",
    "# ---- Pull arrays ----\n",
    "X_train = download_numpy_from_minio(minio_client, bucket_name, object_names[\"X_train\"])\n",
    "y_train = download_numpy_from_minio(minio_client, bucket_name, object_names[\"y_train\"])\n",
    "X_val   = download_numpy_from_minio(minio_client, bucket_name, object_names[\"X_val\"])\n",
    "y_val   = download_numpy_from_minio(minio_client, bucket_name, object_names[\"y_val\"])\n",
    "\n",
    "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"X_val:  \", X_val.shape,   \"y_val:  \", y_val.shape)\n",
    "\n",
    "def make_loader(X, y, batch_size=32, shuffle=True):\n",
    "    ds = TensorDataset(\n",
    "        torch.tensor(X, dtype=torch.float32),\n",
    "        torch.tensor(y, dtype=torch.float32),\n",
    "    )\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=shuffle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411897ef-1899-4c23-aa64-a1c889ac9f12",
   "metadata": {},
   "source": [
    "### 3 Model & training utils (plots, metrics, early stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "144e3101-d6a1-458f-a8c2-5d73850b48c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMForecaster(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, dropout=0.1, horizon=1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, horizon)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, T, F]\n",
    "        out, _ = self.lstm(x)       # [B, T, H]\n",
    "        out = out[:, -1, :]         # [B, H] last step\n",
    "        out = self.fc(out)          # [B, horizon]\n",
    "        return out.unsqueeze(-1)    # [B, horizon, 1] to match y\n",
    "\n",
    "def compute_metrics(loader, model):\n",
    "    \"\"\"Return (MAE, RMSE, R2), along with flattened preds & targets for plotting.\"\"\"\n",
    "    model.eval()\n",
    "    preds, targs = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            pr = model(xb)\n",
    "            preds.append(pr.numpy())\n",
    "            targs.append(yb.numpy())\n",
    "    preds = np.concatenate(preds, axis=0).reshape(-1)\n",
    "    targs = np.concatenate(targs, axis=0).reshape(-1)\n",
    "    mae = mean_absolute_error(targs, preds)\n",
    "    mse = mean_squared_error(targs, preds)\n",
    "    rmse = math.sqrt(mse)\n",
    "    r2 = r2_score(targs, preds)\n",
    "    return (mae, rmse, r2), preds, targs\n",
    "\n",
    "def plot_and_log_learning_curves(train_curve, val_curve, filename=\"learning_curve.png\"):\n",
    "    plt.figure(figsize=(7,3))\n",
    "    plt.plot(train_curve, label=\"train\")\n",
    "    plt.plot(val_curve, label=\"val\")\n",
    "    plt.legend(); plt.title(\"Learning Curve\"); plt.tight_layout()\n",
    "    plt.savefig(filename); plt.close()\n",
    "    mlflow.log_artifact(filename)\n",
    "\n",
    "def plot_and_log_residuals(preds, targs, filename=\"residuals.png\"):\n",
    "    plt.figure(figsize=(7,3))\n",
    "    plt.plot(preds - targs, label=\"residual\")\n",
    "    plt.axhline(0, color=\"black\", linewidth=0.8)\n",
    "    plt.legend(); plt.title(\"Residuals (val)\"); plt.tight_layout()\n",
    "    plt.savefig(filename); plt.close()\n",
    "    mlflow.log_artifact(filename)\n",
    "\n",
    "def plot_and_log_true_vs_pred(targs, preds, filename=\"val_true_vs_pred.png\"):\n",
    "    plt.figure(figsize=(7,3))\n",
    "    plt.plot(targs, label=\"true\")\n",
    "    plt.plot(preds, label=\"pred\")\n",
    "    plt.legend(); plt.title(\"True vs Pred (val)\"); plt.tight_layout()\n",
    "    plt.savefig(filename); plt.close()\n",
    "    mlflow.log_artifact(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f586c5c7-2569-4701-85df-31c8a1700c4f",
   "metadata": {},
   "source": [
    "### 4 — Single-run trainer (used by both trials & final), nested run aware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc388d48-df12-440d-9973-13e1bc0af0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_model_nested(\n",
    "    X_train, y_train, X_val, y_val,\n",
    "    hidden_size=64, num_layers=2, dropout=0.1,\n",
    "    lr=1e-3, batch_size=32,\n",
    "    epochs=35, patience=5,\n",
    "    window_size=None, horizon=None,\n",
    "    run_name=\"trial\",\n",
    "    nested=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains one model, logs to MLflow (as nested run if nested=True),\n",
    "    returns (best_val_loss, run_id, metrics_dict).\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cpu\")\n",
    "    train_loader = make_loader(X_train, y_train, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = make_loader(X_val,   y_val,   batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    input_size = X_train.shape[-1]\n",
    "    if window_size is None: window_size = X_train.shape[1]\n",
    "    if horizon is None:     horizon = y_train.shape[1]\n",
    "\n",
    "    model = LSTMForecaster(\n",
    "        input_size=input_size,\n",
    "        hidden_size=hidden_size,\n",
    "        num_layers=num_layers,\n",
    "        dropout=dropout,\n",
    "        horizon=horizon,\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    opt = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "    patience_left = patience\n",
    "    best_state = None\n",
    "    train_curve, val_curve = [], []\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name, nested=nested) as active_run:\n",
    "        # Log params once\n",
    "        mlflow.log_params({\n",
    "            \"hidden_size\": hidden_size,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"dropout\": dropout,\n",
    "            \"lr\": lr,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"epochs\": epochs,\n",
    "            \"patience\": patience,\n",
    "            \"window_size\": window_size,\n",
    "            \"horizon\": horizon,\n",
    "        })\n",
    "\n",
    "        for ep in range(1, epochs + 1):\n",
    "            # Train\n",
    "            model.train()\n",
    "            running = 0.0\n",
    "            for xb, yb in train_loader:\n",
    "                opt.zero_grad()\n",
    "                pred = model(xb)\n",
    "                loss = criterion(pred, yb)\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "                running += loss.item()\n",
    "            train_loss = running / max(1, len(train_loader))\n",
    "\n",
    "            # Validate\n",
    "            model.eval()\n",
    "            v_running = 0.0\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in val_loader:\n",
    "                    pr = model(xb)\n",
    "                    vloss = criterion(pr, yb)\n",
    "                    v_running += vloss.item()\n",
    "            val_loss = v_running / max(1, len(val_loader))\n",
    "\n",
    "            train_curve.append(train_loss)\n",
    "            val_curve.append(val_loss)\n",
    "\n",
    "            # Log per-epoch\n",
    "            mlflow.log_metric(\"train_loss\", train_loss, step=ep)\n",
    "            mlflow.log_metric(\"val_loss\", val_loss, step=ep)\n",
    "\n",
    "            # Early stopping\n",
    "            if val_loss < best_val - 1e-8:\n",
    "                best_val = val_loss\n",
    "                patience_left = patience\n",
    "                best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            else:\n",
    "                patience_left -= 1\n",
    "                if patience_left <= 0:\n",
    "                    print(\"Early stopping!\")\n",
    "                    break\n",
    "\n",
    "        # Restore best weights & compute final metrics on val\n",
    "        if best_state is not None:\n",
    "            model.load_state_dict(best_state)\n",
    "        (mae, rmse, r2), preds, targs = compute_metrics(val_loader, model)\n",
    "\n",
    "        # Log final metrics & plots\n",
    "        mlflow.log_metric(\"val_mae\", mae)\n",
    "        mlflow.log_metric(\"val_rmse\", rmse)\n",
    "        mlflow.log_metric(\"val_r2\", r2)\n",
    "\n",
    "        plot_and_log_learning_curves(train_curve, val_curve)\n",
    "        plot_and_log_residuals(preds, targs)\n",
    "        plot_and_log_true_vs_pred(targs, preds)\n",
    "\n",
    "        # Save model\n",
    "        mlflow.pytorch.log_model(model, \"model\")\n",
    "\n",
    "        run_id = active_run.info.run_id\n",
    "\n",
    "    metrics = {\"val_loss\": best_val, \"val_mae\": mae, \"val_rmse\": rmse, \"val_r2\": r2}\n",
    "    return best_val, run_id, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7af7621a-5c84-4e98-8459-9ba4fef1d452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "########### 2 MODIFIED VERSION################\n",
    "##############################\n",
    "## Addind I/o schema to the model\n",
    "\n",
    "def train_one_model_nested(\n",
    "    X_train, y_train, X_val, y_val,\n",
    "    hidden_size=64, num_layers=2, dropout=0.1,\n",
    "    lr=1e-3, batch_size=32,\n",
    "    epochs=35, patience=5,\n",
    "    window_size=None, horizon=None,\n",
    "    run_name=\"trial\",\n",
    "    nested=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains one model, logs to MLflow (as nested run if nested=True),\n",
    "    returns (best_val_loss, run_id, metrics_dict).\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cpu\")\n",
    "    train_loader = make_loader(X_train, y_train, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = make_loader(X_val,   y_val,   batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    input_size = X_train.shape[-1]\n",
    "    if window_size is None: window_size = X_train.shape[1]\n",
    "    if horizon is None:     horizon = y_train.shape[1]\n",
    "\n",
    "    model = LSTMForecaster(\n",
    "        input_size=input_size,\n",
    "        hidden_size=hidden_size,\n",
    "        num_layers=num_layers,\n",
    "        dropout=dropout,\n",
    "        horizon=horizon,\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    opt = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "    patience_left = patience\n",
    "    best_state = None\n",
    "    train_curve, val_curve = [], []\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name, nested=nested) as active_run:\n",
    "        # Log params once\n",
    "        mlflow.log_params({\n",
    "            \"hidden_size\": hidden_size,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"dropout\": dropout,\n",
    "            \"lr\": lr,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"epochs\": epochs,\n",
    "            \"patience\": patience,\n",
    "            \"window_size\": window_size,\n",
    "            \"horizon\": horizon,\n",
    "        })\n",
    "\n",
    "        for ep in range(1, epochs + 1):\n",
    "            # Train\n",
    "            model.train()\n",
    "            running = 0.0\n",
    "            for xb, yb in train_loader:\n",
    "                opt.zero_grad()\n",
    "                pred = model(xb)\n",
    "                loss = criterion(pred, yb)\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "                running += loss.item()\n",
    "            train_loss = running / max(1, len(train_loader))\n",
    "\n",
    "            # Validate\n",
    "            model.eval()\n",
    "            v_running = 0.0\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in val_loader:\n",
    "                    pr = model(xb)\n",
    "                    vloss = criterion(pr, yb)\n",
    "                    v_running += vloss.item()\n",
    "            val_loss = v_running / max(1, len(val_loader))\n",
    "\n",
    "            train_curve.append(train_loss)\n",
    "            val_curve.append(val_loss)\n",
    "\n",
    "            # Log per-epoch\n",
    "            mlflow.log_metric(\"train_loss\", train_loss, step=ep)\n",
    "            mlflow.log_metric(\"val_loss\", val_loss, step=ep)\n",
    "\n",
    "            # Early stopping\n",
    "            if val_loss < best_val - 1e-8:\n",
    "                best_val = val_loss\n",
    "                patience_left = patience\n",
    "                best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            else:\n",
    "                patience_left -= 1\n",
    "                if patience_left <= 0:\n",
    "                    print(\"Early stopping!\")\n",
    "                    break\n",
    "\n",
    "        # Restore best weights & compute final metrics on val\n",
    "        if best_state is not None:\n",
    "            model.load_state_dict(best_state)\n",
    "        (mae, rmse, r2), preds, targs = compute_metrics(val_loader, model)\n",
    "\n",
    "        # Log final metrics & plots\n",
    "        mlflow.log_metric(\"val_mae\", mae)\n",
    "        mlflow.log_metric(\"val_rmse\", rmse)\n",
    "        mlflow.log_metric(\"val_r2\", r2)\n",
    "\n",
    "        plot_and_log_learning_curves(train_curve, val_curve)\n",
    "        plot_and_log_residuals(preds, targs)\n",
    "        plot_and_log_true_vs_pred(targs, preds)\n",
    "\n",
    "                ## --------- Build input_example + signature and log the model (FIXED) ---------\n",
    "        # Take one validation sample with the real shape [1, window, 1]\n",
    "        sample_input_t = torch.tensor(X_val[:1], dtype=torch.float32)     # torch tensor\n",
    "        with torch.no_grad():\n",
    "            sample_output_np = model(sample_input_t).detach().cpu().numpy()  # numpy [1, 1, 1]\n",
    "        \n",
    "        #  MLflow requires numpy/pandas (not torch.Tensor) for input_example\n",
    "        input_example_np = sample_input_t.cpu().numpy()  # [1, window, 1]\n",
    "        \n",
    "        # Infer signature from numpy arrays\n",
    "        signature = infer_signature(\n",
    "            input_example_np,   # inputs:  [1, 5, 1] in your case [batch, window, feature]\n",
    "            sample_output_np    # outputs: [1, 1, 1] [batch, horizon, 1]\n",
    "        )\n",
    "        \n",
    "        # Log PyTorch model WITH signature + input_example (no more warning)\n",
    "        mlflow.pytorch.log_model(\n",
    "            model,\n",
    "            artifact_path=\"model\",\n",
    "            input_example=input_example_np,   # <-- numpy, not torch\n",
    "            signature=signature\n",
    "        )\n",
    "        # ---------------------------------------------------------------------------\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "\n",
    "        run_id = active_run.info.run_id\n",
    "\n",
    "    metrics = {\"val_loss\": best_val, \"val_mae\": mae, \"val_rmse\": rmse, \"val_r2\": r2}\n",
    "    return best_val, run_id, metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c6980c-4a78-42c7-a390-7f3336b9591a",
   "metadata": {},
   "source": [
    "### 5 — Optuna objective (each trial becomes a nested run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "32a949e7-0c3d-4a25-a6e1-114927d017c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = X_train.shape[1]  # should be 5\n",
    "HORIZON     = y_train.shape[1]  # should be 1\n",
    "\n",
    "def objective(trial: optuna.Trial):\n",
    "    # Search space\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 16, 128, step=16)\n",
    "    num_layers  = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "    dropout     = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "    lr          = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "    batch_size  = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
    "    epochs      = trial.suggest_int(\"epochs\", 15, 50)\n",
    "    patience    = trial.suggest_int(\"patience\", 3, 10)\n",
    "\n",
    "    # Train one trial as a NESTED MLflow run\n",
    "    val_loss, run_id, metrics = train_one_model_nested(\n",
    "        X_train, y_train, X_val, y_val,\n",
    "        hidden_size=hidden_size, num_layers=num_layers, dropout=dropout,\n",
    "        lr=lr, batch_size=batch_size, epochs=epochs, patience=patience,\n",
    "        window_size=WINDOW_SIZE, horizon=HORIZON,\n",
    "        run_name=f\"trial-{trial.number}\",\n",
    "        nested=True\n",
    "    )\n",
    "\n",
    "    # Attach run id to trial for traceability\n",
    "    trial.set_user_attr(\"mlflow_run_id\", run_id)\n",
    "    # Report for pruning\n",
    "    trial.report(val_loss, step=epochs)\n",
    "    if trial.should_prune():\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return val_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912a8ea4-ce32-40a4-87b0-f6c434d141c5",
   "metadata": {},
   "source": [
    "### 6 — Orchestrator: Parent run → nested trials → nested final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b9ffbea2-40ba-4eef-8742-7f92476baaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hpo_and_final_training(\n",
    "    n_trials=8,\n",
    "    pruner=None,            # e.g., PercentilePruner(percentage=50, n_startup_trials=3)\n",
    "    study_name=\"cpu_pct_lstm\",\n",
    "    parent_run_name=\"session\",\n",
    "    register_model=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a PARENT MLflow run.\n",
    "    - Inside it, runs Optuna trials as nested runs.\n",
    "    - Trains a final best model as another nested run.\n",
    "    - Logs a summary artifact in the parent.\n",
    "    Returns: dict with summary (best params, child run ids, final run id, etc.)\n",
    "    \"\"\"\n",
    "    # Default pruner if not provided\n",
    "    if pruner is None:\n",
    "        pruner = PercentilePruner(percent=50, n_startup_trials=3)\n",
    "\n",
    "    summary = {}\n",
    "    trial_infos = []\n",
    "\n",
    "    with mlflow.start_run(run_name=parent_run_name, nested=False) as parent_run:\n",
    "        parent_run_id = parent_run.info.run_id\n",
    "        mlflow.set_tag(\"session\", parent_run_name)\n",
    "\n",
    "        # --- HPO (trials) ---\n",
    "        study = optuna.create_study(direction=\"minimize\", pruner=pruner, study_name=study_name)\n",
    "        study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
    "\n",
    "        best_params = study.best_params\n",
    "        best_value  = study.best_value\n",
    "        best_trial  = study.best_trial.number\n",
    "\n",
    "        # collect trial metadata (trial -> run_id)\n",
    "        for t in study.trials:\n",
    "            trial_infos.append({\n",
    "                \"trial_number\": t.number,\n",
    "                \"value\": t.value,\n",
    "                \"params\": t.params,\n",
    "                \"state\": str(t.state),\n",
    "                \"mlflow_run_id\": t.user_attrs.get(\"mlflow_run_id\", None),\n",
    "            })\n",
    "\n",
    "        # log to parent\n",
    "        mlflow.log_param(\"n_trials\", n_trials)\n",
    "        mlflow.log_param(\"study_name\", study_name)\n",
    "        mlflow.log_metric(\"best_val_loss\", best_value)\n",
    "        mlflow.set_tag(\"best_trial_number\", best_trial)\n",
    "        for k, v in best_params.items():\n",
    "            mlflow.log_param(f\"best_{k}\", v)\n",
    "\n",
    "        # Save trial summary JSON as artifact\n",
    "        with open(\"optuna_trials_summary.json\", \"w\") as f:\n",
    "            json.dump(trial_infos, f, indent=2)\n",
    "        mlflow.log_artifact(\"optuna_trials_summary.json\")\n",
    "\n",
    "        # --- Final training (nested) ---\n",
    "        final_val_loss, final_run_id, final_metrics = train_one_model_nested(\n",
    "            X_train, y_train, X_val, y_val,\n",
    "            hidden_size=best_params[\"hidden_size\"],\n",
    "            num_layers=best_params[\"num_layers\"],\n",
    "            dropout=best_params[\"dropout\"],\n",
    "            lr=best_params[\"lr\"],\n",
    "            batch_size=best_params[\"batch_size\"],\n",
    "            epochs=best_params[\"epochs\"],\n",
    "            patience=best_params[\"patience\"],\n",
    "            window_size=WINDOW_SIZE,\n",
    "            horizon=HORIZON,\n",
    "            run_name=\"final-best\",\n",
    "            nested=True\n",
    "        )\n",
    "\n",
    "        # Optionally register best model from the final nested run\n",
    "        registered_version = None\n",
    "        if register_model:\n",
    "            model_uri = f\"runs:/{final_run_id}/model\"\n",
    "            registered = mlflow.register_model(model_uri, REGISTERED_MODEL_NAME)\n",
    "            registered_version = registered.version\n",
    "            mlflow.set_tag(\"registered_model_name\", REGISTERED_MODEL_NAME)\n",
    "            mlflow.set_tag(\"registered_model_version\", registered_version)\n",
    "\n",
    "        # build return summary\n",
    "        summary = {\n",
    "            \"parent_run_id\": parent_run_id,\n",
    "            \"best_trial_number\": best_trial,\n",
    "            \"best_params\": best_params,\n",
    "            \"best_val_loss\": best_value,\n",
    "            \"trial_infos\": trial_infos,\n",
    "            \"final_run_id\": final_run_id,\n",
    "            \"final_metrics\": final_metrics,\n",
    "            \"registered_model_name\": REGISTERED_MODEL_NAME if register_model else None,\n",
    "            \"registered_model_version\": registered_version,\n",
    "            \"mlflow_ui_session\": f\"{TRACKING_URI}/#/experiments/{ml_client.get_experiment_by_name(EXPERIMENT_NAME).experiment_id}/runs/{parent_run_id}\"\n",
    "        }\n",
    "\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0d3fc5a7-73e4-438b-a963-d4eac9dd47eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "########### 2 MODIFIED VERSION################\n",
    "##############################\n",
    "## Addind I/o schema to the model\n",
    "def run_hpo_and_final_training(\n",
    "    n_trials=8,\n",
    "    pruner=None,            # e.g., PercentilePruner(percentage=50, n_startup_trials=3)\n",
    "    study_name=\"cpu_pct_lstm\",\n",
    "    parent_run_name=\"session\",\n",
    "    register_model=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a PARENT MLflow run.\n",
    "    - Inside it, runs Optuna trials as nested runs.\n",
    "    - Trains a final best model as another nested run.\n",
    "    - Logs a summary artifact in the parent.\n",
    "    Returns: dict with summary (best params, child run ids, final run id, etc.)\n",
    "    \"\"\"\n",
    "    # Default pruner if not provided\n",
    "    if pruner is None:\n",
    "        pruner = PercentilePruner(percent=50, n_startup_trials=3)\n",
    "\n",
    "    summary = {}\n",
    "    trial_infos = []\n",
    "\n",
    "    with mlflow.start_run(run_name=parent_run_name, nested=False) as parent_run:\n",
    "        parent_run_id = parent_run.info.run_id\n",
    "        mlflow.set_tag(\"session\", parent_run_name)\n",
    "\n",
    "        # --- HPO (trials) ---\n",
    "        study = optuna.create_study(direction=\"minimize\", pruner=pruner, study_name=study_name)\n",
    "        study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
    "\n",
    "        best_params = study.best_params\n",
    "        best_value  = study.best_value\n",
    "        best_trial  = study.best_trial.number\n",
    "\n",
    "        # collect trial metadata (trial -> run_id)\n",
    "        for t in study.trials:\n",
    "            trial_infos.append({\n",
    "                \"trial_number\": t.number,\n",
    "                \"value\": t.value,\n",
    "                \"params\": t.params,\n",
    "                \"state\": str(t.state),\n",
    "                \"mlflow_run_id\": t.user_attrs.get(\"mlflow_run_id\", None),\n",
    "            })\n",
    "\n",
    "        # log to parent\n",
    "        mlflow.log_param(\"n_trials\", n_trials)\n",
    "        mlflow.log_param(\"study_name\", study_name)\n",
    "        mlflow.log_metric(\"best_val_loss\", best_value)\n",
    "        mlflow.set_tag(\"best_trial_number\", best_trial)\n",
    "        for k, v in best_params.items():\n",
    "            mlflow.log_param(f\"best_{k}\", v)\n",
    "\n",
    "        # Save trial summary JSON as artifact\n",
    "        with open(\"optuna_trials_summary.json\", \"w\") as f:\n",
    "            json.dump(trial_infos, f, indent=2)\n",
    "        mlflow.log_artifact(\"optuna_trials_summary.json\")\n",
    "\n",
    "        # --- Final training (nested) ---\n",
    "        final_val_loss, final_run_id, final_metrics = train_one_model_nested(\n",
    "            X_train, y_train, X_val, y_val,\n",
    "            hidden_size=best_params[\"hidden_size\"],\n",
    "            num_layers=best_params[\"num_layers\"],\n",
    "            dropout=best_params[\"dropout\"],\n",
    "            lr=best_params[\"lr\"],\n",
    "            batch_size=best_params[\"batch_size\"],\n",
    "            epochs=best_params[\"epochs\"],\n",
    "            patience=best_params[\"patience\"],\n",
    "            window_size=WINDOW_SIZE,\n",
    "            horizon=HORIZON,\n",
    "            run_name=\"final-best\",\n",
    "            nested=True\n",
    "        )\n",
    "        '''\n",
    "        # Optionally register best model from the final nested run\n",
    "        registered_version = None\n",
    "        if register_model:\n",
    "            model_uri = f\"runs:/{final_run_id}/model\"\n",
    "            registered = mlflow.register_model(model_uri, REGISTERED_MODEL_NAME)\n",
    "            registered_version = registered.version\n",
    "\n",
    "            # Tag the parent run (optional)\n",
    "            mlflow.set_tag(\"registered_model_name\", REGISTERED_MODEL_NAME)\n",
    "            mlflow.set_tag(\"registered_model_version\", registered_version)\n",
    "\n",
    "            # ---- NEW: add tags to the registered model version ----\n",
    "            ml_client.set_model_version_tag(\n",
    "                name=REGISTERED_MODEL_NAME, version=registered_version,\n",
    "                key=\"candidate\", value=\"true\"\n",
    "            )\n",
    "            ml_client.set_model_version_tag(\n",
    "                name=REGISTERED_MODEL_NAME, version=registered_version,\n",
    "                key=\"window\", value=str(WINDOW_SIZE)\n",
    "            )\n",
    "            ml_client.set_model_version_tag(\n",
    "                name=REGISTERED_MODEL_NAME, version=registered_version,\n",
    "                key=\"horizon\", value=str(HORIZON)\n",
    "            )\n",
    "            ml_client.set_model_version_tag(\n",
    "                name=REGISTERED_MODEL_NAME, version=registered_version,\n",
    "                key=\"source_run_id\", value=final_run_id\n",
    "            )\n",
    "            ml_client.set_model_version_tag(\n",
    "                name=REGISTERED_MODEL_NAME, version=registered_version,\n",
    "                key=\"val_rmse\", value=f\"{final_metrics['val_rmse']:.6f}\"\n",
    "            )\n",
    "            ml_client.set_model_version_tag(\n",
    "                name=REGISTERED_MODEL_NAME, version=registered_version,\n",
    "                key=\"val_mae\", value=f\"{final_metrics['val_mae']:.6f}\"\n",
    "            )\n",
    "            ml_client.set_model_version_tag(\n",
    "                name=REGISTERED_MODEL_NAME, version=registered_version,\n",
    "                key=\"val_r2\", value=f\"{final_metrics['val_r2']:.6f}\"\n",
    "            )\n",
    "            # --------------------------------------------------------\n",
    "        '''\n",
    "\n",
    "        # build return summary\n",
    "        summary = {\n",
    "            \"parent_run_id\": parent_run_id,\n",
    "            \"best_trial_number\": best_trial,\n",
    "            \"best_params\": best_params,\n",
    "            \"best_val_loss\": best_value,\n",
    "            \"trial_infos\": trial_infos,\n",
    "            \"final_run_id\": final_run_id,\n",
    "            \"final_metrics\": final_metrics,\n",
    "            \"registered_model_name\": REGISTERED_MODEL_NAME if register_model else None,\n",
    "            #\"registered_model_version\": registered_version,\n",
    "            \"mlflow_ui_session\": f\"{TRACKING_URI}/#/experiments/{ml_client.get_experiment_by_name(EXPERIMENT_NAME).experiment_id}/runs/{parent_run_id}\"\n",
    "        }\n",
    "\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd3f452-ca78-4dd2-980e-e6f49b860df3",
   "metadata": {},
   "source": [
    "### 7 — Run everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2367906b-80c9-40d1-8d6d-e3002cb0dddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 16:33:47,285] A new study created in memory with name: cpu_pct_lstm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 16:34:55 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 16:34:57 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "[I 2025-09-05 16:34:58,071] Trial 0 finished with value: 0.0005779082191090078 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.33663442283128364, 'lr': 0.0006734909980398197, 'batch_size': 16, 'epochs': 39, 'patience': 8}. Best is trial 0 with value: 0.0005779082191090078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run trial-0 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/81d99c39e82d46c3b21345d4f3584f09\n",
      "🧪 View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n"
     ]
    }
   ],
   "source": [
    "summary = run_hpo_and_final_training(\n",
    "    n_trials=3,\n",
    "    pruner=PercentilePruner(percentile=50, n_startup_trials=3),\n",
    "    study_name=\"cpu_pct_lstm\",\n",
    "    parent_run_name=\"cpu-pct-session\",\n",
    "    register_model=True,  # set False if you don't want to register now\n",
    ")\n",
    "\n",
    "print(json.dumps(summary, indent=2))\n",
    "print(\"\\n👀 Open MLflow session run:\", summary[\"mlflow_ui_session\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dbda3c-6b9e-49c8-bcfc-22c09579e0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
