{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95fb9783-619d-40d2-a0f6-d073a4e0001c",
   "metadata": {},
   "source": [
    "# 1 CASE\n",
    "\n",
    "Uses optuna to improve the stage 2. Every run optuna creates is registered in the mlflow and finally label the final best version model.\n",
    "\n",
    "No uses nested runs, so it can be added in case you plan to have multiple runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99e77ae-57b9-41a2-b7c8-ba10e23706ac",
   "metadata": {},
   "source": [
    "### 1.Imports & config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1d3e061-badd-4570-865f-efcac7dfc31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- core\n",
    "import os, io, math, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "\n",
    "# minio\n",
    "from minio import Minio\n",
    "\n",
    "# --- mlflow\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# --- torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# --- metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# --- hpo\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner, PercentilePruner\n",
    "\n",
    "# --- plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ====== Update these for your cluster ======\n",
    "TRACKING_URI = \"http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080\"\n",
    "EXPERIMENT_NAME = \"k8s-cpu-forecasting\"\n",
    "REGISTERED_MODEL_NAME = \"cpu-pct-hpo\"   # MLflow model name\n",
    "\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "client = MlflowClient()\n",
    "\n",
    "# Minio client\n",
    "minio_client = Minio(\n",
    "    \"minio-service.kubeflow.svc.cluster.local:9000\",\n",
    "    access_key=\"minio\",\n",
    "    secret_key=\"minio123\",\n",
    "    secure=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2188713d-50ea-421f-b3e9-d0a1ceddd7ba",
   "metadata": {},
   "source": [
    "### 2 â€” MinIO helpers (reuse your existing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0d71933-c18e-40b0-af23-e43e9e45f729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (8238, 5, 1) y_train: (8238, 1, 1)\n",
      "X_val:   (2060, 5, 1) y_val:   (2060, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "def download_numpy_from_minio(minio_client, bucket_name, object_name):\n",
    "    resp = minio_client.get_object(bucket_name, object_name)\n",
    "    try:\n",
    "        data = resp.read()\n",
    "        arr = np.load(BytesIO(data))\n",
    "        return arr\n",
    "    finally:\n",
    "        resp.close()\n",
    "        resp.release_conn()\n",
    "\n",
    "# Set your paths\n",
    "bucket_name = \"k8s-resources-forecast\"\n",
    "object_names = {\n",
    "    \"X_train\": \"data/k8s-preprocessed/node-1-X_train/X_train.npy\",\n",
    "    \"y_train\": \"data/k8s-preprocessed/node-1-y_train/y_train.npy\",\n",
    "    \"X_val\":   \"data/k8s-preprocessed/node-1-X_test/X_test.npy\",\n",
    "    \"y_val\":   \"data/k8s-preprocessed/node-1-y_test/y_test.npy\",\n",
    "}\n",
    "\n",
    "# Download arrays\n",
    "X_train = download_numpy_from_minio(minio_client, bucket_name, object_names[\"X_train\"])\n",
    "y_train = download_numpy_from_minio(minio_client, bucket_name, object_names[\"y_train\"])\n",
    "X_val   = download_numpy_from_minio(minio_client, bucket_name, object_names[\"X_val\"])\n",
    "y_val   = download_numpy_from_minio(minio_client, bucket_name, object_names[\"y_val\"])\n",
    "\n",
    "# Torch loaders\n",
    "def make_loader(X, y, batch_size, shuffle):\n",
    "    ds = TensorDataset(torch.tensor(X, dtype=torch.float32),\n",
    "                       torch.tensor(y, dtype=torch.float32))\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "# sanity\n",
    "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"X_val:  \", X_val.shape,   \"y_val:  \", y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cdd665-c5fd-4848-8117-7dc830984f1f",
   "metadata": {},
   "source": [
    "### 3 â€” Model, train loop, metrics & plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df543f1f-7f9a-406b-be14-5d4b43dea398",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMForecaster(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, dropout=0.0, horizon=1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,\n",
    "                            batch_first=True, dropout=dropout if num_layers > 1 else 0.0)\n",
    "        self.fc   = nn.Linear(hidden_size, horizon)  # horizon outputs\n",
    "    def forward(self, x):\n",
    "        # x: [B, T, F]\n",
    "        out, _ = self.lstm(x)             # [B, T, H]\n",
    "        out = out[:, -1, :]               # last step [B, H]\n",
    "        out = self.fc(out)                # [B, horizon]\n",
    "        return out.unsqueeze(-1)          # [B, horizon, 1] to match y\n",
    "\n",
    "def train_one_model(X_train, y_train, X_val, y_val,\n",
    "                    hidden_size, num_layers, dropout,\n",
    "                    lr, batch_size, epochs, patience, window_size, horizon,\n",
    "                    run_name=None):\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "    train_loader = make_loader(X_train, y_train, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = make_loader(X_val,   y_val,   batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = LSTMForecaster(input_size=X_train.shape[-1],\n",
    "                           hidden_size=hidden_size,\n",
    "                           num_layers=num_layers,\n",
    "                           dropout=dropout,\n",
    "                           horizon=horizon).to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    opt = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "    patience_left = patience\n",
    "    train_curve, val_curve = [], []\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        mlflow.log_params({\n",
    "            \"hidden_size\": hidden_size,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"dropout\": dropout,\n",
    "            \"lr\": lr,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"epochs\": epochs,\n",
    "            \"patience\": patience,\n",
    "            \"window_size\": window_size,\n",
    "            \"horizon\": horizon\n",
    "        })\n",
    "\n",
    "        for ep in range(1, epochs + 1):\n",
    "            # --- train ---\n",
    "            model.train()\n",
    "            running = 0.0\n",
    "            for xb, yb in train_loader:\n",
    "                opt.zero_grad()\n",
    "                pred = model(xb)\n",
    "                loss = criterion(pred, yb)\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "                running += loss.item()\n",
    "            train_loss = running / max(1, len(train_loader))\n",
    "\n",
    "            # --- validate ---\n",
    "            model.eval()\n",
    "            v_running = 0.0\n",
    "            preds, targs = [], []\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in val_loader:\n",
    "                    pr = model(xb)\n",
    "                    v_loss = criterion(pr, yb)\n",
    "                    v_running += v_loss.item()\n",
    "                    preds.append(pr.numpy())\n",
    "                    targs.append(yb.numpy())\n",
    "            val_loss = v_running / max(1, len(val_loader))\n",
    "            train_curve.append(train_loss)\n",
    "            val_curve.append(val_loss)\n",
    "\n",
    "            # log per-epoch for MLflow + Optuna pruning\n",
    "            mlflow.log_metric(\"train_loss\", train_loss, step=ep)\n",
    "            mlflow.log_metric(\"val_loss\",   val_loss,   step=ep)\n",
    "\n",
    "            # early stopping\n",
    "            if val_loss < best_val - 1e-8:\n",
    "                best_val = val_loss\n",
    "                patience_left = patience\n",
    "                best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            else:\n",
    "                patience_left -= 1\n",
    "                if patience_left <= 0:\n",
    "                    print(\"Early stopping!\")\n",
    "                    break\n",
    "\n",
    "        # restore best\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "        # Final val metrics (MAE/RMSE/R2)\n",
    "        preds = np.concatenate([model(xb).detach().numpy() for xb, _ in val_loader], axis=0).reshape(-1)\n",
    "        targs = np.concatenate([yb.numpy() for _, yb in val_loader], axis=0).reshape(-1)\n",
    "        mae  = mean_absolute_error(targs, preds)\n",
    "        mse  = mean_squared_error(targs, preds)\n",
    "        rmse = math.sqrt(mse)\n",
    "        r2   = r2_score(targs, preds)\n",
    "\n",
    "        mlflow.log_metric(\"val_mae\", mae)\n",
    "        mlflow.log_metric(\"val_rmse\", rmse)\n",
    "        mlflow.log_metric(\"val_r2\", r2)\n",
    "\n",
    "        # plots: learning curve, residuals, true vs pred\n",
    "        # 1) Learning curve\n",
    "        plt.figure(figsize=(6,3))\n",
    "        plt.plot(train_curve, label=\"train\")\n",
    "        plt.plot(val_curve, label=\"val\")\n",
    "        plt.legend(); plt.title(\"Learning Curve\"); plt.tight_layout()\n",
    "        plt.savefig(\"learning_curve.png\"); plt.close()\n",
    "        mlflow.log_artifact(\"learning_curve.png\")\n",
    "\n",
    "        # 2) Residuals over time\n",
    "        plt.figure(figsize=(6,3))\n",
    "        plt.plot(preds - targs, label=\"residual\")\n",
    "        plt.axhline(0, color=\"black\", linewidth=0.8)\n",
    "        plt.legend(); plt.title(\"Residuals (val)\"); plt.tight_layout()\n",
    "        plt.savefig(\"residuals.png\"); plt.close()\n",
    "        mlflow.log_artifact(\"residuals.png\")\n",
    "\n",
    "        # 3) True vs Pred\n",
    "        plt.figure(figsize=(6,3))\n",
    "        plt.plot(targs, label=\"true\")\n",
    "        plt.plot(preds, label=\"pred\")\n",
    "        plt.legend(); plt.title(\"True vs Pred (val)\"); plt.tight_layout()\n",
    "        plt.savefig(\"val_true_vs_pred.png\"); plt.close()\n",
    "        mlflow.log_artifact(\"val_true_vs_pred.png\")\n",
    "\n",
    "        # Save model to MLflow\n",
    "        mlflow.pytorch.log_model(model, \"model\")\n",
    "\n",
    "        # Return metrics (for Optuna) and the run_id\n",
    "        run_id = mlflow.active_run().info.run_id\n",
    "    return model, {\"val_loss\": best_val, \"mae\": mae, \"rmse\": rmse, \"r2\": r2}, run_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d73166-f879-46cb-b360-aec5f32c6781",
   "metadata": {},
   "source": [
    "### 4 â€” Optuna objective & study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2e46882-a3dc-4541-9ad5-99b5943b60f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 12:28:02,592] A new study created in memory with name: cpu_pct_lstm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 12:28:51 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 12:28:54 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 12:28:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 12:28:54,476] Trial 0 finished with value: 0.0007080256194643345 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.17196126146370536, 'lr': 0.003127900843950967, 'batch_size': 16, 'epochs': 46, 'patience': 4}. Best is trial 0 with value: 0.0007080256194643345.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run optuna-trial-0 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/a42ea83f26e74755a7d569e6084f497e\n",
      "ðŸ§ª View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 12:29:29 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 12:29:32 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 12:29:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 12:29:32,313] Trial 1 finished with value: 0.000550303586130736 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.20657423557430274, 'lr': 0.0004770825259355593, 'batch_size': 64, 'epochs': 49, 'patience': 8}. Best is trial 1 with value: 0.000550303586130736.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run optuna-trial-1 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/e47e07df73994507b31761ed942c11eb\n",
      "ðŸ§ª View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 12:30:00 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 12:30:03 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 12:30:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 12:30:03,494] Trial 2 finished with value: 0.0005593707155919849 and parameters: {'hidden_size': 96, 'num_layers': 1, 'dropout': 0.3801576987716789, 'lr': 0.0003339794978128798, 'batch_size': 32, 'epochs': 49, 'patience': 7}. Best is trial 1 with value: 0.000550303586130736.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run optuna-trial-2 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/e4e2e057d74a4816b375f76af064e1b8\n",
      "ðŸ§ª View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 12:31:15 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 12:31:17 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 12:31:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 12:31:17,868] Trial 3 finished with value: 0.0005508742245952957 and parameters: {'hidden_size': 80, 'num_layers': 3, 'dropout': 0.27795352066203954, 'lr': 0.0004255807011022233, 'batch_size': 32, 'epochs': 44, 'patience': 10}. Best is trial 1 with value: 0.000550303586130736.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run optuna-trial-3 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/ddffc0c2ac4e43edb7579d2879a99c07\n",
      "ðŸ§ª View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 12:31:53 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 12:31:55 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 12:31:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 12:31:55,993] Trial 4 finished with value: 0.0008058777809289262 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.1170797146384416, 'lr': 0.0018520909012747725, 'batch_size': 16, 'epochs': 48, 'patience': 3}. Best is trial 1 with value: 0.000550303586130736.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run optuna-trial-4 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/cb05852583664ab6b2f5a9ba6b3e72ca\n",
      "ðŸ§ª View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 12:32:10 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 12:32:13 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 12:32:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 12:32:13,189] Trial 5 finished with value: 0.0005694188520115298 and parameters: {'hidden_size': 80, 'num_layers': 1, 'dropout': 0.11710905649009723, 'lr': 0.004394327634441767, 'batch_size': 32, 'epochs': 18, 'patience': 8}. Best is trial 1 with value: 0.000550303586130736.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run optuna-trial-5 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/8c8e38e0fb134642a2ddab236c6207b4\n",
      "ðŸ§ª View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 12:32:43 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 12:32:46 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 12:32:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 12:32:46,790] Trial 6 finished with value: 0.0005730214435562072 and parameters: {'hidden_size': 16, 'num_layers': 2, 'dropout': 0.026416992261014818, 'lr': 0.0012471602055676436, 'batch_size': 16, 'epochs': 45, 'patience': 4}. Best is trial 1 with value: 0.000550303586130736.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run optuna-trial-6 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/12e219e69e9b4e479ea67d95cf1f527f\n",
      "ðŸ§ª View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 12:33:01 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 12:33:04 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 12:33:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 12:33:04,632] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run optuna-trial-7 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/68da9be44b144977a62c211eae8dc877\n",
      "ðŸ§ª View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 12:33:55 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 12:33:58 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 12:33:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 12:33:58,717] Trial 8 finished with value: 0.0005629137305041068 and parameters: {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.32868231920620256, 'lr': 0.0002442776272584786, 'batch_size': 16, 'epochs': 46, 'patience': 10}. Best is trial 1 with value: 0.000550303586130736.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run optuna-trial-8 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/c0d749030e9346968107dd66d417cd9b\n",
      "ðŸ§ª View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 12:34:31 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 12:34:34 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 12:34:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 12:34:34,240] Trial 9 finished with value: 0.0005474657589343913 and parameters: {'hidden_size': 48, 'num_layers': 2, 'dropout': 0.3125423900604701, 'lr': 0.0002844212723489982, 'batch_size': 64, 'epochs': 46, 'patience': 6}. Best is trial 9 with value: 0.0005474657589343913.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run optuna-trial-9 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/7a6172ba96ec43a387b1f34dcb944cf4\n",
      "ðŸ§ª View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 12:35:13 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 12:35:16 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 12:35:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 12:35:16,683] Trial 10 finished with value: 0.000710926936748861 and parameters: {'hidden_size': 16, 'num_layers': 3, 'dropout': 0.2614810083185243, 'lr': 0.00018991236345418773, 'batch_size': 64, 'epochs': 34, 'patience': 6}. Best is trial 9 with value: 0.0005474657589343913.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run optuna-trial-10 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/6c596918b57140a38601a9095aeb98a1\n",
      "ðŸ§ª View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 12:36:09 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 12:36:11 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 12:36:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 12:36:11,871] Trial 11 finished with value: 0.0005757764191719506 and parameters: {'hidden_size': 48, 'num_layers': 3, 'dropout': 0.21740591526050054, 'lr': 0.00012412149478993346, 'batch_size': 64, 'epochs': 35, 'patience': 8}. Best is trial 9 with value: 0.0005474657589343913.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run optuna-trial-11 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/6707703efcfa4435a33dfdef8ac329a9\n",
      "ðŸ§ª View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Best trial: 9\n",
      "Best value (val_loss): 0.0005474657589343913\n",
      "Best params: {'hidden_size': 48, 'num_layers': 2, 'dropout': 0.3125423900604701, 'lr': 0.0002844212723489982, 'batch_size': 64, 'epochs': 46, 'patience': 6}\n"
     ]
    }
   ],
   "source": [
    "# Define the search space and objective\n",
    "WINDOW_SIZE = X_train.shape[1]  # should be 5 in your case\n",
    "HORIZON     = y_train.shape[1]  # 1\n",
    "\n",
    "def objective(trial: optuna.Trial):\n",
    "    # Hyperparameter search space\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 16, 128, step=16)\n",
    "    num_layers  = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "    dropout     = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "    lr          = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "    batch_size  = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
    "    epochs      = trial.suggest_int(\"epochs\", 15, 50)\n",
    "    patience    = trial.suggest_int(\"patience\", 3, 10)\n",
    "\n",
    "    # Train & get val metrics\n",
    "    _, metrics, run_id = train_one_model(\n",
    "        X_train, y_train, X_val, y_val,\n",
    "        hidden_size, num_layers, dropout,\n",
    "        lr, batch_size, epochs, patience,\n",
    "        WINDOW_SIZE, HORIZON,\n",
    "        run_name=f\"optuna-trial-{trial.number}\"\n",
    "    )\n",
    "\n",
    "    # report intermediate to enable pruning\n",
    "    trial.report(metrics[\"val_loss\"], step=epochs)\n",
    "    if trial.should_prune():\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    # Attach the MLflow run_id to the trial for traceability\n",
    "    trial.set_user_attr(\"mlflow_run_id\", run_id)\n",
    "    return metrics[\"val_loss\"]\n",
    "\n",
    "# Create study (minimize val_loss) with pruning\n",
    "pruner = PercentilePruner(percentile=50, n_startup_trials=3, n_warmup_steps=0)\n",
    "study = optuna.create_study(direction=\"minimize\", pruner=pruner, study_name=\"cpu_pct_lstm\")\n",
    "\n",
    "# Run optimization\n",
    "N_TRIALS = 12\n",
    "study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=False)\n",
    "\n",
    "print(\"Best trial:\", study.best_trial.number)\n",
    "print(\"Best value (val_loss):\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b213bcd6-b617-4464-88ea-36db6a612def",
   "metadata": {},
   "source": [
    "### 5 â€” Train final model on (train+val), evaluate test, log & register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22417587-4b9e-4227-b7a0-b40a6334ff1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8db5332d-ad67-4c0c-a666-e5ed8fe04d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 12:36:28 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 12:36:30 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 12:36:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Successfully registered model 'cpu-pct-hpo'.\n",
      "2025/09/05 12:36:31 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: cpu-pct-hpo, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run final-best at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/dd7985f8fbc04803b71b23852e6c045d\n",
      "ðŸ§ª View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "âœ… Registered model: cpu-pct-hpo version: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'cpu-pct-hpo'.\n"
     ]
    }
   ],
   "source": [
    "# If you also have a held-out test set, load it (or repurpose X_val/y_val as test)\n",
    "# Here, we'll just evaluate on the existing val set for demonstration\n",
    "best = study.best_params\n",
    "\n",
    "# Re-train once with best params (optionally combine train+val for final fit)\n",
    "final_model, final_metrics, run_id = train_one_model(\n",
    "    X_train, y_train, X_val, y_val,\n",
    "    best[\"hidden_size\"], best[\"num_layers\"], best[\"dropout\"],\n",
    "    best[\"lr\"], best[\"batch_size\"], best[\"epochs\"], best[\"patience\"],\n",
    "    WINDOW_SIZE, HORIZON,\n",
    "    run_name=\"final-best\"\n",
    ")\n",
    "\n",
    "# Register in MLflow Model Registry\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "result = mlflow.register_model(model_uri, REGISTERED_MODEL_NAME)\n",
    "print(\"âœ… Registered model:\", result.name, \"version:\", result.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3ee177-f75a-4b79-bdd1-9c395e961fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c8bec2e-88e0-4055-9cce-5f1aec1b9dd8",
   "metadata": {},
   "source": [
    "# 2 CASE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "88ea14fe-a4ad-47e2-9064-b3a1287e79ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080 Experiment: k8s-cpu-forecasting\n"
     ]
    }
   ],
   "source": [
    "# ----- Core -----\n",
    "import os, io, json, math, random\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ----- MLflow -----\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# ----- Torch -----\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# ----- Metrics -----\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# ----- HPO -----\n",
    "import optuna\n",
    "from optuna.pruners import PercentilePruner\n",
    "\n",
    "# ----- Plotting -----\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----- Repro -----\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "set_seed(42)\n",
    "\n",
    "# ===== MLflow tracking =====\n",
    "TRACKING_URI = \"http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080\"\n",
    "EXPERIMENT_NAME = \"k8s-cpu-forecasting\"\n",
    "REGISTERED_MODEL_NAME = \"cpu-pct\"     # model registry name (optional but nice)\n",
    "\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "ml_client = MlflowClient()\n",
    "\n",
    "print(\"MLflow:\", TRACKING_URI, \"Experiment:\", EXPERIMENT_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ab4ab6-b914-452f-83af-3888971f6b43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1c4feb8c-24ca-48f8-9be7-fd6a360d71c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (8238, 5, 1) y_train: (8238, 1, 1)\n",
      "X_val:   (2060, 5, 1) y_val:   (2060, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "from minio import Minio\n",
    "\n",
    "# If you already have `minio_client`, you can skip this cell.\n",
    "# Adjust endpoint/creds to your cluster.\n",
    "MINIO_ENDPOINT = \"minio-service.kubeflow.svc.cluster.local:9000\"\n",
    "MINIO_ACCESS_KEY = \"minio\"\n",
    "MINIO_SECRET_KEY = \"minio123\"\n",
    "\n",
    "minio_client = Minio(\n",
    "    endpoint=MINIO_ENDPOINT,\n",
    "    access_key=MINIO_ACCESS_KEY,\n",
    "    secret_key=MINIO_SECRET_KEY,\n",
    "    secure=False\n",
    ")\n",
    "\n",
    "def download_numpy_from_minio(minio_client, bucket_name: str, object_name: str) -> np.ndarray:\n",
    "    \"\"\"Download a .npy as numpy array (in-memory, no temp file).\"\"\"\n",
    "    resp = minio_client.get_object(bucket_name, object_name)\n",
    "    try:\n",
    "        data = resp.read()\n",
    "        arr = np.load(BytesIO(data))\n",
    "        return arr\n",
    "    finally:\n",
    "        resp.close()\n",
    "        resp.release_conn()\n",
    "\n",
    "# ---- Paths for your prepared arrays ----\n",
    "bucket_name = \"k8s-resources-forecast\"\n",
    "object_names = {\n",
    "    \"X_train\": \"data/k8s-preprocessed/node-1-X_train/X_train.npy\",\n",
    "    \"y_train\": \"data/k8s-preprocessed/node-1-y_train/y_train.npy\",\n",
    "    \"X_val\":   \"data/k8s-preprocessed/node-1-X_test/X_test.npy\",\n",
    "    \"y_val\":   \"data/k8s-preprocessed/node-1-y_test/y_test.npy\",\n",
    "}\n",
    "\n",
    "# ---- Pull arrays ----\n",
    "X_train = download_numpy_from_minio(minio_client, bucket_name, object_names[\"X_train\"])\n",
    "y_train = download_numpy_from_minio(minio_client, bucket_name, object_names[\"y_train\"])\n",
    "X_val   = download_numpy_from_minio(minio_client, bucket_name, object_names[\"X_val\"])\n",
    "y_val   = download_numpy_from_minio(minio_client, bucket_name, object_names[\"y_val\"])\n",
    "\n",
    "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"X_val:  \", X_val.shape,   \"y_val:  \", y_val.shape)\n",
    "\n",
    "def make_loader(X, y, batch_size=32, shuffle=True):\n",
    "    ds = TensorDataset(\n",
    "        torch.tensor(X, dtype=torch.float32),\n",
    "        torch.tensor(y, dtype=torch.float32),\n",
    "    )\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164561ad-af8d-45fa-badf-585a1516ab55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "144e3101-d6a1-458f-a8c2-5d73850b48c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMForecaster(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, dropout=0.1, horizon=1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, horizon)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, T, F]\n",
    "        out, _ = self.lstm(x)       # [B, T, H]\n",
    "        out = out[:, -1, :]         # [B, H] last step\n",
    "        out = self.fc(out)          # [B, horizon]\n",
    "        return out.unsqueeze(-1)    # [B, horizon, 1] to match y\n",
    "\n",
    "def compute_metrics(loader, model):\n",
    "    \"\"\"Return (MAE, RMSE, R2), along with flattened preds & targets for plotting.\"\"\"\n",
    "    model.eval()\n",
    "    preds, targs = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            pr = model(xb)\n",
    "            preds.append(pr.numpy())\n",
    "            targs.append(yb.numpy())\n",
    "    preds = np.concatenate(preds, axis=0).reshape(-1)\n",
    "    targs = np.concatenate(targs, axis=0).reshape(-1)\n",
    "    mae = mean_absolute_error(targs, preds)\n",
    "    mse = mean_squared_error(targs, preds)\n",
    "    rmse = math.sqrt(mse)\n",
    "    r2 = r2_score(targs, preds)\n",
    "    return (mae, rmse, r2), preds, targs\n",
    "\n",
    "def plot_and_log_learning_curves(train_curve, val_curve, filename=\"learning_curve.png\"):\n",
    "    plt.figure(figsize=(7,3))\n",
    "    plt.plot(train_curve, label=\"train\")\n",
    "    plt.plot(val_curve, label=\"val\")\n",
    "    plt.legend(); plt.title(\"Learning Curve\"); plt.tight_layout()\n",
    "    plt.savefig(filename); plt.close()\n",
    "    mlflow.log_artifact(filename)\n",
    "\n",
    "def plot_and_log_residuals(preds, targs, filename=\"residuals.png\"):\n",
    "    plt.figure(figsize=(7,3))\n",
    "    plt.plot(preds - targs, label=\"residual\")\n",
    "    plt.axhline(0, color=\"black\", linewidth=0.8)\n",
    "    plt.legend(); plt.title(\"Residuals (val)\"); plt.tight_layout()\n",
    "    plt.savefig(filename); plt.close()\n",
    "    mlflow.log_artifact(filename)\n",
    "\n",
    "def plot_and_log_true_vs_pred(targs, preds, filename=\"val_true_vs_pred.png\"):\n",
    "    plt.figure(figsize=(7,3))\n",
    "    plt.plot(targs, label=\"true\")\n",
    "    plt.plot(preds, label=\"pred\")\n",
    "    plt.legend(); plt.title(\"True vs Pred (val)\"); plt.tight_layout()\n",
    "    plt.savefig(filename); plt.close()\n",
    "    mlflow.log_artifact(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d93763-4d94-4a67-811d-8f4024ff6aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc388d48-df12-440d-9973-13e1bc0af0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_model_nested(\n",
    "    X_train, y_train, X_val, y_val,\n",
    "    hidden_size=64, num_layers=2, dropout=0.1,\n",
    "    lr=1e-3, batch_size=32,\n",
    "    epochs=35, patience=5,\n",
    "    window_size=None, horizon=None,\n",
    "    run_name=\"trial\",\n",
    "    nested=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains one model, logs to MLflow (as nested run if nested=True),\n",
    "    returns (best_val_loss, run_id, metrics_dict).\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cpu\")\n",
    "    train_loader = make_loader(X_train, y_train, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = make_loader(X_val,   y_val,   batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    input_size = X_train.shape[-1]\n",
    "    if window_size is None: window_size = X_train.shape[1]\n",
    "    if horizon is None:     horizon = y_train.shape[1]\n",
    "\n",
    "    model = LSTMForecaster(\n",
    "        input_size=input_size,\n",
    "        hidden_size=hidden_size,\n",
    "        num_layers=num_layers,\n",
    "        dropout=dropout,\n",
    "        horizon=horizon,\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    opt = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "    patience_left = patience\n",
    "    best_state = None\n",
    "    train_curve, val_curve = [], []\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name, nested=nested) as active_run:\n",
    "        # Log params once\n",
    "        mlflow.log_params({\n",
    "            \"hidden_size\": hidden_size,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"dropout\": dropout,\n",
    "            \"lr\": lr,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"epochs\": epochs,\n",
    "            \"patience\": patience,\n",
    "            \"window_size\": window_size,\n",
    "            \"horizon\": horizon,\n",
    "        })\n",
    "\n",
    "        for ep in range(1, epochs + 1):\n",
    "            # Train\n",
    "            model.train()\n",
    "            running = 0.0\n",
    "            for xb, yb in train_loader:\n",
    "                opt.zero_grad()\n",
    "                pred = model(xb)\n",
    "                loss = criterion(pred, yb)\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "                running += loss.item()\n",
    "            train_loss = running / max(1, len(train_loader))\n",
    "\n",
    "            # Validate\n",
    "            model.eval()\n",
    "            v_running = 0.0\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in val_loader:\n",
    "                    pr = model(xb)\n",
    "                    vloss = criterion(pr, yb)\n",
    "                    v_running += vloss.item()\n",
    "            val_loss = v_running / max(1, len(val_loader))\n",
    "\n",
    "            train_curve.append(train_loss)\n",
    "            val_curve.append(val_loss)\n",
    "\n",
    "            # Log per-epoch\n",
    "            mlflow.log_metric(\"train_loss\", train_loss, step=ep)\n",
    "            mlflow.log_metric(\"val_loss\", val_loss, step=ep)\n",
    "\n",
    "            # Early stopping\n",
    "            if val_loss < best_val - 1e-8:\n",
    "                best_val = val_loss\n",
    "                patience_left = patience\n",
    "                best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            else:\n",
    "                patience_left -= 1\n",
    "                if patience_left <= 0:\n",
    "                    print(\"Early stopping!\")\n",
    "                    break\n",
    "\n",
    "        # Restore best weights & compute final metrics on val\n",
    "        if best_state is not None:\n",
    "            model.load_state_dict(best_state)\n",
    "        (mae, rmse, r2), preds, targs = compute_metrics(val_loader, model)\n",
    "\n",
    "        # Log final metrics & plots\n",
    "        mlflow.log_metric(\"val_mae\", mae)\n",
    "        mlflow.log_metric(\"val_rmse\", rmse)\n",
    "        mlflow.log_metric(\"val_r2\", r2)\n",
    "\n",
    "        plot_and_log_learning_curves(train_curve, val_curve)\n",
    "        plot_and_log_residuals(preds, targs)\n",
    "        plot_and_log_true_vs_pred(targs, preds)\n",
    "\n",
    "        # Save model\n",
    "        mlflow.pytorch.log_model(model, \"model\")\n",
    "\n",
    "        run_id = active_run.info.run_id\n",
    "\n",
    "    metrics = {\"val_loss\": best_val, \"val_mae\": mae, \"val_rmse\": rmse, \"val_r2\": r2}\n",
    "    return best_val, run_id, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a653df04-5650-46e5-aa44-2df8013f0337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "32a949e7-0c3d-4a25-a6e1-114927d017c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = X_train.shape[1]  # should be 5\n",
    "HORIZON     = y_train.shape[1]  # should be 1\n",
    "\n",
    "def objective(trial: optuna.Trial):\n",
    "    # Search space\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 16, 128, step=16)\n",
    "    num_layers  = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "    dropout     = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "    lr          = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "    batch_size  = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
    "    epochs      = trial.suggest_int(\"epochs\", 15, 50)\n",
    "    patience    = trial.suggest_int(\"patience\", 3, 10)\n",
    "\n",
    "    # Train one trial as a NESTED MLflow run\n",
    "    val_loss, run_id, metrics = train_one_model_nested(\n",
    "        X_train, y_train, X_val, y_val,\n",
    "        hidden_size=hidden_size, num_layers=num_layers, dropout=dropout,\n",
    "        lr=lr, batch_size=batch_size, epochs=epochs, patience=patience,\n",
    "        window_size=WINDOW_SIZE, horizon=HORIZON,\n",
    "        run_name=f\"trial-{trial.number}\",\n",
    "        nested=True\n",
    "    )\n",
    "\n",
    "    # Attach run id to trial for traceability\n",
    "    trial.set_user_attr(\"mlflow_run_id\", run_id)\n",
    "    # Report for pruning\n",
    "    trial.report(val_loss, step=epochs)\n",
    "    if trial.should_prune():\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b9ffbea2-40ba-4eef-8742-7f92476baaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hpo_and_final_training(\n",
    "    n_trials=8,\n",
    "    pruner=None,            # e.g., PercentilePruner(percentage=50, n_startup_trials=3)\n",
    "    study_name=\"cpu_pct_lstm\",\n",
    "    parent_run_name=\"session\",\n",
    "    register_model=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a PARENT MLflow run.\n",
    "    - Inside it, runs Optuna trials as nested runs.\n",
    "    - Trains a final best model as another nested run.\n",
    "    - Logs a summary artifact in the parent.\n",
    "    Returns: dict with summary (best params, child run ids, final run id, etc.)\n",
    "    \"\"\"\n",
    "    # Default pruner if not provided\n",
    "    if pruner is None:\n",
    "        pruner = PercentilePruner(percent=50, n_startup_trials=3)\n",
    "\n",
    "    summary = {}\n",
    "    trial_infos = []\n",
    "\n",
    "    with mlflow.start_run(run_name=parent_run_name, nested=False) as parent_run:\n",
    "        parent_run_id = parent_run.info.run_id\n",
    "        mlflow.set_tag(\"session\", parent_run_name)\n",
    "\n",
    "        # --- HPO (trials) ---\n",
    "        study = optuna.create_study(direction=\"minimize\", pruner=pruner, study_name=study_name)\n",
    "        study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
    "\n",
    "        best_params = study.best_params\n",
    "        best_value  = study.best_value\n",
    "        best_trial  = study.best_trial.number\n",
    "\n",
    "        # collect trial metadata (trial -> run_id)\n",
    "        for t in study.trials:\n",
    "            trial_infos.append({\n",
    "                \"trial_number\": t.number,\n",
    "                \"value\": t.value,\n",
    "                \"params\": t.params,\n",
    "                \"state\": str(t.state),\n",
    "                \"mlflow_run_id\": t.user_attrs.get(\"mlflow_run_id\", None),\n",
    "            })\n",
    "\n",
    "        # log to parent\n",
    "        mlflow.log_param(\"n_trials\", n_trials)\n",
    "        mlflow.log_param(\"study_name\", study_name)\n",
    "        mlflow.log_metric(\"best_val_loss\", best_value)\n",
    "        mlflow.set_tag(\"best_trial_number\", best_trial)\n",
    "        for k, v in best_params.items():\n",
    "            mlflow.log_param(f\"best_{k}\", v)\n",
    "\n",
    "        # Save trial summary JSON as artifact\n",
    "        with open(\"optuna_trials_summary.json\", \"w\") as f:\n",
    "            json.dump(trial_infos, f, indent=2)\n",
    "        mlflow.log_artifact(\"optuna_trials_summary.json\")\n",
    "\n",
    "        # --- Final training (nested) ---\n",
    "        final_val_loss, final_run_id, final_metrics = train_one_model_nested(\n",
    "            X_train, y_train, X_val, y_val,\n",
    "            hidden_size=best_params[\"hidden_size\"],\n",
    "            num_layers=best_params[\"num_layers\"],\n",
    "            dropout=best_params[\"dropout\"],\n",
    "            lr=best_params[\"lr\"],\n",
    "            batch_size=best_params[\"batch_size\"],\n",
    "            epochs=best_params[\"epochs\"],\n",
    "            patience=best_params[\"patience\"],\n",
    "            window_size=WINDOW_SIZE,\n",
    "            horizon=HORIZON,\n",
    "            run_name=\"final-best\",\n",
    "            nested=True\n",
    "        )\n",
    "\n",
    "        # Optionally register best model from the final nested run\n",
    "        registered_version = None\n",
    "        if register_model:\n",
    "            model_uri = f\"runs:/{final_run_id}/model\"\n",
    "            registered = mlflow.register_model(model_uri, REGISTERED_MODEL_NAME)\n",
    "            registered_version = registered.version\n",
    "            mlflow.set_tag(\"registered_model_name\", REGISTERED_MODEL_NAME)\n",
    "            mlflow.set_tag(\"registered_model_version\", registered_version)\n",
    "\n",
    "        # build return summary\n",
    "        summary = {\n",
    "            \"parent_run_id\": parent_run_id,\n",
    "            \"best_trial_number\": best_trial,\n",
    "            \"best_params\": best_params,\n",
    "            \"best_val_loss\": best_value,\n",
    "            \"trial_infos\": trial_infos,\n",
    "            \"final_run_id\": final_run_id,\n",
    "            \"final_metrics\": final_metrics,\n",
    "            \"registered_model_name\": REGISTERED_MODEL_NAME if register_model else None,\n",
    "            \"registered_model_version\": registered_version,\n",
    "            \"mlflow_ui_session\": f\"{TRACKING_URI}/#/experiments/{ml_client.get_experiment_by_name(EXPERIMENT_NAME).experiment_id}/runs/{parent_run_id}\"\n",
    "        }\n",
    "\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2367906b-80c9-40d1-8d6d-e3002cb0dddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 13:40:06,445] A new study created in memory with name: cpu_pct_lstm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 13:40:51 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 13:40:54 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 13:40:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 13:40:54,193] Trial 0 finished with value: 0.0005527776212507295 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.21594938963242113, 'lr': 0.001035867811094136, 'batch_size': 16, 'epochs': 27, 'patience': 4}. Best is trial 0 with value: 0.0005527776212507295.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run trial-0 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/f1eece9b992d46228d4fc12b0726b558\n",
      "ðŸ§ª View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 13:41:34 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 13:41:37 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 13:41:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 13:41:37,635] Trial 1 finished with value: 0.0005516582446244473 and parameters: {'hidden_size': 80, 'num_layers': 2, 'dropout': 0.13146413348549732, 'lr': 0.0002057123347351767, 'batch_size': 32, 'epochs': 16, 'patience': 5}. Best is trial 1 with value: 0.0005516582446244473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run trial-1 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/c91fe35b9c07423397a3932958d482e0\n",
      "ðŸ§ª View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 13:44:29 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 13:44:32 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 13:44:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 13:44:32,253] Trial 2 finished with value: 0.0005883132114324199 and parameters: {'hidden_size': 80, 'num_layers': 3, 'dropout': 0.026820471100354393, 'lr': 0.0034939485416015234, 'batch_size': 16, 'epochs': 26, 'patience': 8}. Best is trial 1 with value: 0.0005516582446244473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run trial-2 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/7aff3d53f7e14ad48e059d4f89d59965\n",
      "ðŸ§ª View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 13:46:52 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 13:46:55 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 13:46:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 13:46:55,344] Trial 3 finished with value: 0.0005895734918953548 and parameters: {'hidden_size': 48, 'num_layers': 3, 'dropout': 0.12974596361687527, 'lr': 0.0018237788732962288, 'batch_size': 16, 'epochs': 24, 'patience': 10}. Best is trial 1 with value: 0.0005516582446244473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run trial-3 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/2c8e8991476245a38f0f39e401b374e1\n",
      "ðŸ§ª View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 13:47:25 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 13:47:28 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 13:47:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 13:47:28,299] Trial 4 finished with value: 0.0007164971448360155 and parameters: {'hidden_size': 48, 'num_layers': 3, 'dropout': 0.32268152115910104, 'lr': 0.003671774149292361, 'batch_size': 16, 'epochs': 47, 'patience': 3}. Best is trial 1 with value: 0.0005516582446244473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run trial-4 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/7262ab5bd42347c09c86d0be01320a3f\n",
      "ðŸ§ª View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 13:47:48 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 13:47:51 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 13:47:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 13:47:51,455] Trial 5 finished with value: 0.0006404745867117667 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.09033688524389612, 'lr': 0.003103161141244499, 'batch_size': 32, 'epochs': 19, 'patience': 7}. Best is trial 1 with value: 0.0005516582446244473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run trial-5 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/193f41038c5548389bb3291949bb5fa3\n",
      "ðŸ§ª View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 13:49:35 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 13:49:37 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 13:49:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 13:49:38,013] Trial 6 finished with value: 0.0005471934855449945 and parameters: {'hidden_size': 80, 'num_layers': 3, 'dropout': 0.13959564423989423, 'lr': 0.00017799899768228584, 'batch_size': 32, 'epochs': 35, 'patience': 10}. Best is trial 6 with value: 0.0005471934855449945.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run trial-6 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/879b706c9ac346aea35e33058f35abe5\n",
      "ðŸ§ª View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 13:49:49 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 13:49:52 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 13:49:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 13:49:52,492] Trial 7 finished with value: 0.0006421489524655044 and parameters: {'hidden_size': 80, 'num_layers': 1, 'dropout': 0.2159554306213737, 'lr': 0.00080749013512319, 'batch_size': 16, 'epochs': 18, 'patience': 3}. Best is trial 6 with value: 0.0005471934855449945.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run trial-7 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/8d6305fa26c04494b5d650f230c5840c\n",
      "ðŸ§ª View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 13:50:26 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 13:50:28 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 13:50:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 13:50:28,870] Trial 8 finished with value: 0.0005548046221604657 and parameters: {'hidden_size': 80, 'num_layers': 1, 'dropout': 0.30481101953835205, 'lr': 0.0006210091911101955, 'batch_size': 16, 'epochs': 33, 'patience': 9}. Best is trial 6 with value: 0.0005471934855449945.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run trial-8 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/e55882d7a8ab4e28aeb964e2723b7f3c\n",
      "ðŸ§ª View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 13:50:51 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 13:50:53 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 13:50:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-09-05 13:50:53,853] Trial 9 finished with value: 0.0005775818791544924 and parameters: {'hidden_size': 80, 'num_layers': 2, 'dropout': 0.3263315805624927, 'lr': 0.0020367448517796026, 'batch_size': 32, 'epochs': 32, 'patience': 7}. Best is trial 6 with value: 0.0005471934855449945.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run trial-9 at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/f88b97ad22024922b3dde2b08166c49b\n",
      "ðŸ§ª View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 13:52:33 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/05 13:52:36 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/05 13:52:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Successfully registered model 'cpu-pct'.\n",
      "2025/09/05 13:52:36 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: cpu-pct, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run final-best at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/f047961788c94ce29f5a17499d224ba7\n",
      "ðŸ§ª View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "ðŸƒ View run cpu-pct-session at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/bc43b1ae967d4139b5ad7db110776452\n",
      "ðŸ§ª View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "{\n",
      "  \"parent_run_id\": \"bc43b1ae967d4139b5ad7db110776452\",\n",
      "  \"best_trial_number\": 6,\n",
      "  \"best_params\": {\n",
      "    \"hidden_size\": 80,\n",
      "    \"num_layers\": 3,\n",
      "    \"dropout\": 0.13959564423989423,\n",
      "    \"lr\": 0.00017799899768228584,\n",
      "    \"batch_size\": 32,\n",
      "    \"epochs\": 35,\n",
      "    \"patience\": 10\n",
      "  },\n",
      "  \"best_val_loss\": 0.0005471934855449945,\n",
      "  \"trial_infos\": [\n",
      "    {\n",
      "      \"trial_number\": 0,\n",
      "      \"value\": 0.0005527776212507295,\n",
      "      \"params\": {\n",
      "        \"hidden_size\": 64,\n",
      "        \"num_layers\": 3,\n",
      "        \"dropout\": 0.21594938963242113,\n",
      "        \"lr\": 0.001035867811094136,\n",
      "        \"batch_size\": 16,\n",
      "        \"epochs\": 27,\n",
      "        \"patience\": 4\n",
      "      },\n",
      "      \"state\": \"1\",\n",
      "      \"mlflow_run_id\": \"f1eece9b992d46228d4fc12b0726b558\"\n",
      "    },\n",
      "    {\n",
      "      \"trial_number\": 1,\n",
      "      \"value\": 0.0005516582446244473,\n",
      "      \"params\": {\n",
      "        \"hidden_size\": 80,\n",
      "        \"num_layers\": 2,\n",
      "        \"dropout\": 0.13146413348549732,\n",
      "        \"lr\": 0.0002057123347351767,\n",
      "        \"batch_size\": 32,\n",
      "        \"epochs\": 16,\n",
      "        \"patience\": 5\n",
      "      },\n",
      "      \"state\": \"1\",\n",
      "      \"mlflow_run_id\": \"c91fe35b9c07423397a3932958d482e0\"\n",
      "    },\n",
      "    {\n",
      "      \"trial_number\": 2,\n",
      "      \"value\": 0.0005883132114324199,\n",
      "      \"params\": {\n",
      "        \"hidden_size\": 80,\n",
      "        \"num_layers\": 3,\n",
      "        \"dropout\": 0.026820471100354393,\n",
      "        \"lr\": 0.0034939485416015234,\n",
      "        \"batch_size\": 16,\n",
      "        \"epochs\": 26,\n",
      "        \"patience\": 8\n",
      "      },\n",
      "      \"state\": \"1\",\n",
      "      \"mlflow_run_id\": \"7aff3d53f7e14ad48e059d4f89d59965\"\n",
      "    },\n",
      "    {\n",
      "      \"trial_number\": 3,\n",
      "      \"value\": 0.0005895734918953548,\n",
      "      \"params\": {\n",
      "        \"hidden_size\": 48,\n",
      "        \"num_layers\": 3,\n",
      "        \"dropout\": 0.12974596361687527,\n",
      "        \"lr\": 0.0018237788732962288,\n",
      "        \"batch_size\": 16,\n",
      "        \"epochs\": 24,\n",
      "        \"patience\": 10\n",
      "      },\n",
      "      \"state\": \"1\",\n",
      "      \"mlflow_run_id\": \"2c8e8991476245a38f0f39e401b374e1\"\n",
      "    },\n",
      "    {\n",
      "      \"trial_number\": 4,\n",
      "      \"value\": 0.0007164971448360155,\n",
      "      \"params\": {\n",
      "        \"hidden_size\": 48,\n",
      "        \"num_layers\": 3,\n",
      "        \"dropout\": 0.32268152115910104,\n",
      "        \"lr\": 0.003671774149292361,\n",
      "        \"batch_size\": 16,\n",
      "        \"epochs\": 47,\n",
      "        \"patience\": 3\n",
      "      },\n",
      "      \"state\": \"1\",\n",
      "      \"mlflow_run_id\": \"7262ab5bd42347c09c86d0be01320a3f\"\n",
      "    },\n",
      "    {\n",
      "      \"trial_number\": 5,\n",
      "      \"value\": 0.0006404745867117667,\n",
      "      \"params\": {\n",
      "        \"hidden_size\": 64,\n",
      "        \"num_layers\": 2,\n",
      "        \"dropout\": 0.09033688524389612,\n",
      "        \"lr\": 0.003103161141244499,\n",
      "        \"batch_size\": 32,\n",
      "        \"epochs\": 19,\n",
      "        \"patience\": 7\n",
      "      },\n",
      "      \"state\": \"1\",\n",
      "      \"mlflow_run_id\": \"193f41038c5548389bb3291949bb5fa3\"\n",
      "    },\n",
      "    {\n",
      "      \"trial_number\": 6,\n",
      "      \"value\": 0.0005471934855449945,\n",
      "      \"params\": {\n",
      "        \"hidden_size\": 80,\n",
      "        \"num_layers\": 3,\n",
      "        \"dropout\": 0.13959564423989423,\n",
      "        \"lr\": 0.00017799899768228584,\n",
      "        \"batch_size\": 32,\n",
      "        \"epochs\": 35,\n",
      "        \"patience\": 10\n",
      "      },\n",
      "      \"state\": \"1\",\n",
      "      \"mlflow_run_id\": \"879b706c9ac346aea35e33058f35abe5\"\n",
      "    },\n",
      "    {\n",
      "      \"trial_number\": 7,\n",
      "      \"value\": 0.0006421489524655044,\n",
      "      \"params\": {\n",
      "        \"hidden_size\": 80,\n",
      "        \"num_layers\": 1,\n",
      "        \"dropout\": 0.2159554306213737,\n",
      "        \"lr\": 0.00080749013512319,\n",
      "        \"batch_size\": 16,\n",
      "        \"epochs\": 18,\n",
      "        \"patience\": 3\n",
      "      },\n",
      "      \"state\": \"1\",\n",
      "      \"mlflow_run_id\": \"8d6305fa26c04494b5d650f230c5840c\"\n",
      "    },\n",
      "    {\n",
      "      \"trial_number\": 8,\n",
      "      \"value\": 0.0005548046221604657,\n",
      "      \"params\": {\n",
      "        \"hidden_size\": 80,\n",
      "        \"num_layers\": 1,\n",
      "        \"dropout\": 0.30481101953835205,\n",
      "        \"lr\": 0.0006210091911101955,\n",
      "        \"batch_size\": 16,\n",
      "        \"epochs\": 33,\n",
      "        \"patience\": 9\n",
      "      },\n",
      "      \"state\": \"1\",\n",
      "      \"mlflow_run_id\": \"e55882d7a8ab4e28aeb964e2723b7f3c\"\n",
      "    },\n",
      "    {\n",
      "      \"trial_number\": 9,\n",
      "      \"value\": 0.0005775818791544924,\n",
      "      \"params\": {\n",
      "        \"hidden_size\": 80,\n",
      "        \"num_layers\": 2,\n",
      "        \"dropout\": 0.3263315805624927,\n",
      "        \"lr\": 0.0020367448517796026,\n",
      "        \"batch_size\": 32,\n",
      "        \"epochs\": 32,\n",
      "        \"patience\": 7\n",
      "      },\n",
      "      \"state\": \"1\",\n",
      "      \"mlflow_run_id\": \"f88b97ad22024922b3dde2b08166c49b\"\n",
      "    }\n",
      "  ],\n",
      "  \"final_run_id\": \"f047961788c94ce29f5a17499d224ba7\",\n",
      "  \"final_metrics\": {\n",
      "    \"val_loss\": 0.0005448162580320898,\n",
      "    \"val_mae\": 0.01814059168100357,\n",
      "    \"val_rmse\": 0.02334206243368261,\n",
      "    \"val_r2\": 0.7653113603591919\n",
      "  },\n",
      "  \"registered_model_name\": \"cpu-pct\",\n",
      "  \"registered_model_version\": \"1\",\n",
      "  \"mlflow_ui_session\": \"http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/bc43b1ae967d4139b5ad7db110776452\"\n",
      "}\n",
      "\n",
      "ðŸ‘€ Open MLflow session run: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/bc43b1ae967d4139b5ad7db110776452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'cpu-pct'.\n"
     ]
    }
   ],
   "source": [
    "summary = run_hpo_and_final_training(\n",
    "    n_trials=10,\n",
    "    pruner=PercentilePruner(percentile=50, n_startup_trials=3),\n",
    "    study_name=\"cpu_pct_lstm\",\n",
    "    parent_run_name=\"cpu-pct-session\",\n",
    "    register_model=True,  # set False if you don't want to register now\n",
    ")\n",
    "\n",
    "print(json.dumps(summary, indent=2))\n",
    "print(\"\\nðŸ‘€ Open MLflow session run:\", summary[\"mlflow_ui_session\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dbda3c-6b9e-49c8-bcfc-22c09579e0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
