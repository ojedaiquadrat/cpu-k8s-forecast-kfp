{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "328a1447-01ef-4f9b-abd3-dd4f1626ba3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.21.3\n"
     ]
    }
   ],
   "source": [
    "# pip install uv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8ab4fb7-6974-4986-90bd-524bc729cff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080 Experiment: k8s-cpu-forecasting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec8fdefb758479b88d24ea78439e762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf9f633b2be473c9eab499610252ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/08 13:29:45 INFO mlflow.models.flavor_backend_registry: Selected backend for flavor 'python_function'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a92ff32edf7a4897a893463bf2421727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/08 13:29:46 INFO mlflow.utils.virtualenv: Environment /tmp/tmp3qx6g8wx/envs/virtualenv_envs/mlflow-8c3b8977e6a5a31eb2cc96f87c4418cad74670ab already exists\n",
      "2025/09/08 13:29:46 INFO mlflow.utils.environment: === Running command '['bash', '-c', 'source /tmp/tmp3qx6g8wx/envs/virtualenv_envs/mlflow-8c3b8977e6a5a31eb2cc96f87c4418cad74670ab/bin/activate && python -c \"\"']'\n",
      "2025/09/08 13:29:46 INFO mlflow.utils.environment: === Running command '['bash', '-c', 'source /tmp/tmp3qx6g8wx/envs/virtualenv_envs/mlflow-8c3b8977e6a5a31eb2cc96f87c4418cad74670ab/bin/activate && python /opt/conda/lib/python3.11/site-packages/mlflow/pyfunc/_mlflow_pyfunc_backend_predict.py --model-uri file:///tmp/tmpx52no5g7/2025-09-08-11%3A16%3A55-cpu-node-1-pct-model --content-type json --input-path /tmp/tmpo4u3wj28/input.json']'\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/mlflow/pyfunc/_mlflow_pyfunc_backend_predict.py\", line 7, in <module>\n",
      "    from mlflow.pyfunc.scoring_server import _predict\n",
      "ModuleNotFoundError: No module named 'mlflow'\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "Non-zero exit code: 1\nCommand: ['bash', '-c', 'source /tmp/tmp3qx6g8wx/envs/virtualenv_envs/mlflow-8c3b8977e6a5a31eb2cc96f87c4418cad74670ab/bin/activate && python /opt/conda/lib/python3.11/site-packages/mlflow/pyfunc/_mlflow_pyfunc_backend_predict.py --model-uri file:///tmp/tmpx52no5g7/2025-09-08-11%3A16%3A55-cpu-node-1-pct-model --content-type json --input-path /tmp/tmpo4u3wj28/input.json']\n\nAn exception occurred while running model prediction within a uv environment. You can find the error message from the prediction subprocess by scrolling above.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 25\u001b[0m\n\u001b[1;32m     21\u001b[0m input_data \u001b[38;5;241m=\u001b[39m pyfunc_model\u001b[38;5;241m.\u001b[39minput_example\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# If you run this from a shell where torch==2.8.0 is already installed:\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# disables virtualenv/conda, uses your CURRENT environment\u001b[39;49;00m\n\u001b[1;32m     29\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/mlflow/models/python_api.py:265\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(model_uri, input_data, input_path, content_type, output_path, env_manager, install_mlflow, pip_requirements_override, extra_envs)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(input_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    263\u001b[0m             f\u001b[38;5;241m.\u001b[39mwrite(input_data)\n\u001b[0;32m--> 265\u001b[0m         \u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    267\u001b[0m     _predict(input_path)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/mlflow/models/python_api.py:243\u001b[0m, in \u001b[0;36mpredict.<locals>._predict\u001b[0;34m(_input_path)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_predict\u001b[39m(_input_path: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_flavor_backend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43minstall_mlflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstall_mlflow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpyfunc_backend_env_root_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m--> 243\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_input_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpip_requirements_override\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpip_requirements_override\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_envs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_envs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/mlflow/pyfunc/backend.py:216\u001b[0m, in \u001b[0;36mPyFuncBackend.predict\u001b[0;34m(self, model_uri, input_path, output_path, content_type, pip_requirements_override, extra_envs)\u001b[0m\n\u001b[1;32m    214\u001b[0m         environment\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(predict_cmd))\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ShellCommandException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    217\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAn exception occurred while running model prediction within a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    218\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_env_manager\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m environment. You can find the error message \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom the prediction subprocess by scrolling above.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    220\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pip_requirements_override:\n",
      "\u001b[0;31mMlflowException\u001b[0m: Non-zero exit code: 1\nCommand: ['bash', '-c', 'source /tmp/tmp3qx6g8wx/envs/virtualenv_envs/mlflow-8c3b8977e6a5a31eb2cc96f87c4418cad74670ab/bin/activate && python /opt/conda/lib/python3.11/site-packages/mlflow/pyfunc/_mlflow_pyfunc_backend_predict.py --model-uri file:///tmp/tmpx52no5g7/2025-09-08-11%3A16%3A55-cpu-node-1-pct-model --content-type json --input-path /tmp/tmpo4u3wj28/input.json']\n\nAn exception occurred while running model prediction within a uv environment. You can find the error message from the prediction subprocess by scrolling above."
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.models import Model\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.models import infer_signature\n",
    "import conda\n",
    "import numpy as np\n",
    "\n",
    "# ===== MLflow tracking =====\n",
    "TRACKING_URI = \"http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080\"\n",
    "EXPERIMENT_NAME = \"k8s-cpu-forecasting\"\n",
    "REGISTERED_MODEL_NAME = \"cpu-pct\"     # model registry name (optional but nice)\n",
    "\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "ml_client = MlflowClient()\n",
    "\n",
    "print(\"MLflow:\", TRACKING_URI, \"Experiment:\", EXPERIMENT_NAME)\n",
    "model_uri = 'runs:/c9eee3c98eee4309a0a602339d1ea612/2025-09-08-11:16:55-cpu-node-1-pct-model'\n",
    "# The model is logged with an input example\n",
    "pyfunc_model = mlflow.pyfunc.load_model(model_uri)\n",
    "input_data = pyfunc_model.input_example\n",
    "\n",
    "\n",
    "# If you run this from a shell where torch==2.8.0 is already installed:\n",
    "mlflow.models.predict(\n",
    "    model_uri=model_uri,\n",
    "    input_data=input_data,\n",
    "    env_manager=\"uv\"  # disables virtualenv/conda, uses your CURRENT environment\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7403348a-3bd6-4a71-a9b3-0b6ceb4e5369",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Manual way\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from mlflow.models import Model\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.models import infer_signature\n",
    "import conda\n",
    "\n",
    "print(mlflow.__version__)\n",
    "\n",
    "# ===== MLflow tracking =====\n",
    "TRACKING_URI = \"http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080\"\n",
    "EXPERIMENT_NAME = \"k8s-cpu-forecasting\"\n",
    "REGISTERED_MODEL_NAME = \"cpu-pct\"     # model registry name (optional but nice)\n",
    "\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "ml_client = MlflowClient()\n",
    "\n",
    "print(\"MLflow:\", TRACKING_URI, \"Experiment:\", EXPERIMENT_NAME)\n",
    "\n",
    "model_uri = 'runs:/c9eee3c98eee4309a0a602339d1ea612/2025-09-08-11:16:55-cpu-node-1-pct-model'\n",
    "model = mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "# Use example input shape from MLflow UI\n",
    "input_data = np.array([[\n",
    "    [0.19565217],\n",
    "    [0.22826087],\n",
    "    [0.25],\n",
    "    [0.20652173],\n",
    "    [0.22826087]\n",
    "]],dtype=np.float32)   # shape (1, 5, 1)\n",
    "\n",
    "result = model.predict(input_data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "924fe102-e63b-4bc8-bdb1-f781f74777ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.21144302]]]\n",
      "0.21144302189350128\n"
     ]
    }
   ],
   "source": [
    "pred = pyfunc_model.predict(input_data)\n",
    "print(pred)\n",
    "pred_scalar = float(np.array(pred).squeeze())   # -> just the number\n",
    "print(pred_scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d2010d0f-4044-448d-8fa1-2db56ff353fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single model: runs:/891119da512b479d84ab3fcb6bf4a5fc/2025-09-08-14:25:55-cpu-node-1-pct-model\n",
      "HPO model: runs:/6311c4290f5f4fd9beb5902a2e3ee304/2025-09-08-14:25:55-hpo-cpu-node-1-pct-model\n"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "client = MlflowClient()\n",
    "experiment = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "\n",
    "# Fetch ALL runs, sort by start time DESC (latest first)\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    filter_string=\"\",  # You could filter by tag if you want to\n",
    "    order_by=[\"attributes.start_time DESC\"],\n",
    "    max_results=10  # adjust if needed\n",
    ")\n",
    "\n",
    "# Find your two target runs by `run_name` or `tags`!\n",
    "single_model_run = None\n",
    "hpo_parent_run = None\n",
    "for run in runs:\n",
    "    rn = run.data.tags.get(\"mlflow.runName\", \"\")\n",
    "    if rn.endswith(\"cpu-node-1-forecast\") and not \"hpo\" in rn:\n",
    "        single_model_run = run\n",
    "    if rn.endswith(\"hpo-cpu-node-1-forecast-session\"):\n",
    "        hpo_parent_run = run\n",
    "    # Stop if both found\n",
    "    if single_model_run and hpo_parent_run:\n",
    "        break\n",
    "\n",
    "if not single_model_run or not hpo_parent_run:\n",
    "    raise Exception(\"Could not find both single and HPO runs.\")\n",
    "\n",
    "# For the HPO run, get the FINAL nested run (best model)\n",
    "hpo_child_runs = client.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    filter_string=f\"tags.mlflow.parentRunId = '{hpo_parent_run.info.run_id}'\",\n",
    "    order_by=[\"attributes.start_time DESC\"],\n",
    "    max_results=5\n",
    ")\n",
    "# Find the nested run whose name contains \"final-best\" or similar\n",
    "hpo_best_run = None\n",
    "for run in hpo_child_runs:\n",
    "    rn = run.data.tags.get(\"mlflow.runName\", \"\")\n",
    "    if \"final\" in rn or \"best\" in rn:\n",
    "        hpo_best_run = run\n",
    "        break\n",
    "if not hpo_best_run:\n",
    "    # fallback: just pick the first child run (most recent)\n",
    "    hpo_best_run = hpo_child_runs[0]\n",
    "\n",
    "# Now, get the model URIs\n",
    "timestamp = single_model_run.data.tags.get(\"mlflow.runName\", \"\").split(\"-cpu-node-1-forecast\")[0]\n",
    "single_model_uri = f\"runs:/{single_model_run.info.run_id}/{timestamp}-cpu-node-1-pct-model\"\n",
    "hpo_model_uri = f\"runs:/{hpo_best_run.info.run_id}/{timestamp}-hpo-cpu-node-1-pct-model\"\n",
    "\n",
    "print(\"Single model:\", single_model_uri)\n",
    "print(\"HPO model:\", hpo_model_uri)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782e1c9e-4cab-4c61-beb2-b1bd5bc231f1",
   "metadata": {},
   "source": [
    "### dummy stage 4 valid\n",
    "@dsl.component(\n",
    "    base_image=\"docker.io/jhofydu/pytorch-kfp:v1.0.0\",\n",
    "    packages_to_install=[\"minio\", \"mlflow==2.21.3\", \"uv\", \"virtualenv\"]\n",
    ")\n",
    "def model_validation() -> NamedTuple(\"Outputs\", [(\"hpo_cpu_node_1_forecast\", str)]):\n",
    "    '''\n",
    "    import mlflow\n",
    "    from mlflow.models import Model\n",
    "    from mlflow.tracking import MlflowClient\n",
    "    from mlflow.models import infer_signature\n",
    "    import conda\n",
    "    \n",
    "    # ===== MLflow tracking =====\n",
    "    TRACKING_URI = \"http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080\"\n",
    "    EXPERIMENT_NAME = \"k8s-cpu-forecasting\"\n",
    "    REGISTERED_MODEL_NAME = \"cpu-pct\"     # model registry name (optional but nice)\n",
    "    \n",
    "    mlflow.set_tracking_uri(TRACKING_URI)\n",
    "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "    ml_client = MlflowClient()\n",
    "    \n",
    "    print(\"MLflow:\", TRACKING_URI, \"Experiment:\", EXPERIMENT_NAME)\n",
    "    model_uri = 'runs:/c9eee3c98eee4309a0a602339d1ea612/2025-09-08-11:16:55-cpu-node-1-pct-model'\n",
    "    # The model is logged with an input example\n",
    "    pyfunc_model = mlflow.pyfunc.load_model(model_uri)\n",
    "    input_data = pyfunc_model.input_example\n",
    "    \n",
    "    \n",
    "    # If you run this from a shell where torch==2.8.0 is already installed:\n",
    "    mlflow.models.predict(\n",
    "        model_uri=model_uri,\n",
    "        input_data=input_data,\n",
    "        env_manager=\"conda\"  # disables virtualenv/conda, uses your CURRENT environment\n",
    "    )\n",
    "    '''\n",
    "    import mlflow\n",
    "    import numpy as np\n",
    "    from mlflow.models import Model\n",
    "    from mlflow.tracking import MlflowClient\n",
    "    from mlflow.models import infer_signature\n",
    "    import conda\n",
    "    \n",
    "    print(mlflow.__version__)\n",
    "    \n",
    "    # ===== MLflow tracking =====\n",
    "    TRACKING_URI = \"http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080\"\n",
    "    EXPERIMENT_NAME = \"k8s-cpu-forecasting\"\n",
    "    REGISTERED_MODEL_NAME = \"cpu-pct\"     # model registry name (optional but nice)\n",
    "    \n",
    "    mlflow.set_tracking_uri(TRACKING_URI)\n",
    "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "    ml_client = MlflowClient()\n",
    "    \n",
    "    print(\"MLflow:\", TRACKING_URI, \"Experiment:\", EXPERIMENT_NAME)\n",
    "    \n",
    "    model_uri = 'runs:/c9eee3c98eee4309a0a602339d1ea612/2025-09-08-11:16:55-cpu-node-1-pct-model'\n",
    "    model = mlflow.pyfunc.load_model(model_uri)\n",
    "    \n",
    "    # Use example input shape from MLflow UI\n",
    "    input_data = np.array([[\n",
    "        [0.19565217],\n",
    "        [0.22826087],\n",
    "        [0.25],\n",
    "        [0.20652173],\n",
    "        [0.22826087]\n",
    "    ]],dtype=np.float32)   # shape (1, 5, 1)\n",
    "    \n",
    "    result = model.predict(input_data)\n",
    "    print(result)\n",
    "    output_str = np.array2string(result)\n",
    "    return (output_str,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107a1b7c-736e-4192-bc51-afc63fc6d6b2",
   "metadata": {},
   "source": [
    "# 4STAGE implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544449ce-886e-477b-8e32-fee5e61cd83e",
   "metadata": {},
   "source": [
    "### 1Cell functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "645fdd4f-4a1a-47f1-8d65-391282718c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import numpy as np\n",
    "\n",
    "def setup_mlflow(tracking_uri, experiment_name):\n",
    "    mlflow.set_tracking_uri(tracking_uri)\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    client = MlflowClient()\n",
    "    experiment = client.get_experiment_by_name(experiment_name)\n",
    "    return client, experiment\n",
    "\n",
    "def find_runs(client, experiment_id, single_suffix=\"cpu-node-1-forecast\", hpo_suffix=\"hpo-cpu-node-1-forecast-session\", limit=10):\n",
    "    runs = client.search_runs(\n",
    "        experiment_ids=[experiment_id],\n",
    "        order_by=[\"attributes.start_time DESC\"],\n",
    "        max_results=limit\n",
    "    )\n",
    "    single_run, hpo_parent_run = None, None\n",
    "    for run in runs:\n",
    "        rn = run.data.tags.get(\"mlflow.runName\", \"\")\n",
    "        if rn.endswith(single_suffix) and \"hpo\" not in rn:\n",
    "            single_run = run\n",
    "        if rn.endswith(hpo_suffix):\n",
    "            hpo_parent_run = run\n",
    "        if single_run and hpo_parent_run:\n",
    "            break\n",
    "    if not single_run or not hpo_parent_run:\n",
    "        raise Exception(\"Could not find both single and HPO runs.\")\n",
    "    return single_run, hpo_parent_run\n",
    "\n",
    "def find_final_hpo_child_run(client, experiment_id, parent_run, keyword=\"final-best\"):\n",
    "    hpo_child_runs = client.search_runs(\n",
    "        experiment_ids=[experiment_id],\n",
    "        filter_string=f\"tags.mlflow.parentRunId = '{parent_run.info.run_id}'\",\n",
    "        order_by=[\"attributes.start_time DESC\"],\n",
    "        max_results=10\n",
    "    )\n",
    "    for run in hpo_child_runs:\n",
    "        rn = run.data.tags.get(\"mlflow.runName\", \"\")\n",
    "        if keyword in rn or \"final\" in rn or \"best\" in rn:\n",
    "            return run\n",
    "    return hpo_child_runs[0] if hpo_child_runs else None\n",
    "\n",
    "def build_model_uris(single_run, hpo_run, suffix=\"-cpu-node-1-pct-model\", hpo_suffix=\"-hpo-cpu-node-1-pct-model\"):\n",
    "    timestamp = single_run.data.tags.get(\"mlflow.runName\", \"\").split(\"-cpu-node-1-forecast\")[0]\n",
    "    single_model_uri = f\"runs:/{single_run.info.run_id}/{timestamp}{suffix}\"\n",
    "    hpo_model_uri = f\"runs:/{hpo_run.info.run_id}/{timestamp}{hpo_suffix}\"\n",
    "    print(\"Single model uri:\", single_model_uri)\n",
    "    print(\"HPO model uri:\", hpo_model_uri)\n",
    "    return single_model_uri, hpo_model_uri\n",
    "\n",
    "def validate_model(model_uri, example_input):\n",
    "    import mlflow\n",
    "    model = mlflow.pyfunc.load_model(model_uri)\n",
    "    result = model.predict(example_input)\n",
    "    print(f\"Result for {model_uri}: {result}\")\n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce4456b-3b87-4878-8b60-a47af2bf13fa",
   "metadata": {},
   "source": [
    "### 2 Cell Calling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b6c7941e-f2c9-406a-86e6-311cfcae9c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single model uri: runs:/ed180661112f422ea9b9513ecdf84a94/2025-09-08-14:36:04-cpu-node-1-pct-model\n",
      "HPO model uri: runs:/cb82d7a3937147e98a844b2e649705db/2025-09-08-14:36:04-hpo-cpu-node-1-pct-model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd6cecf92423434b806a9dd4d20199c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for runs:/ed180661112f422ea9b9513ecdf84a94/2025-09-08-14:36:04-cpu-node-1-pct-model: [[[0.22926752]]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb7c5997ead04026ba7ea64e0f32ed24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for runs:/cb82d7a3937147e98a844b2e649705db/2025-09-08-14:36:04-hpo-cpu-node-1-pct-model: [[[0.21611929]]]\n",
      "Single model output prediction: 0.22926752269268036\n",
      "HPO model output:prediction 0.21611928939819336\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TRACKING_URI = \"http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080\"\n",
    "EXPERIMENT_NAME = \"k8s-cpu-forecasting\"\n",
    "\n",
    "client, experiment = setup_mlflow(TRACKING_URI, EXPERIMENT_NAME)\n",
    "single_run, hpo_parent_run = find_runs(client, experiment.experiment_id)\n",
    "hpo_best_run = find_final_hpo_child_run(client, experiment.experiment_id, hpo_parent_run)\n",
    "\n",
    "single_model_uri, hpo_model_uri = build_model_uris(single_run, hpo_best_run)\n",
    "\n",
    "# Example input (replace with your real validation input!)\n",
    "input_data = np.array([[\n",
    "    [0.19565217],\n",
    "    [0.22826087],\n",
    "    [0.25],\n",
    "    [0.20652173],\n",
    "    [0.22826087]\n",
    "]], dtype=np.float32)\n",
    "\n",
    "single_result = validate_model(single_model_uri, input_data)\n",
    "hpo_result = validate_model(hpo_model_uri, input_data)\n",
    "single_result_scalar = float(np.array(single_result).squeeze())   # -> just the number\n",
    "hpo_result_scalar = float(np.array(hpo_result).squeeze())   # -> just the number\n",
    "print(\"Single model output prediction:\", single_result_scalar)\n",
    "print(\"HPO model output:prediction\", hpo_result_scalar)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43fd70e-2210-419a-857f-86abac486d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
