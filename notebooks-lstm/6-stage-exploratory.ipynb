{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5db65d8-5bcf-429e-aa42-db0c6183db0e",
   "metadata": {},
   "source": [
    "# 1. Exploring the MlFlow Storage to deploy the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34884aa6-73a9-416d-a1cc-6f80574e62f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow-artifacts:/27/1bd475a443f94ccaa2085c1c6279216e/artifacts/2025-09-09-14:56:56-hpo-cpu-node-1-pct-model\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080\")\n",
    "client = MlflowClient()\n",
    "\n",
    "mv = client.get_model_version(\"cpu-pct-test-5\", \"1\")   # <- pick your model/version\n",
    "print(mv.source)  # e.g. s3://mlflow/27/3e0850.../artifacts/model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9f400f-abab-4b1b-b85a-54e2439575f0",
   "metadata": {},
   "source": [
    "### Minio fro Mlflow credential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4893968d-fbeb-4c19-b5a5-2e6842d63d4a",
   "metadata": {},
   "source": [
    "kubectl -n mlflow get secrets | grep -i minio\n",
    "\n",
    "# Example for Bitnami chart:\n",
    "kubectl -n mlflow get secret sunrise-minio -o jsonpath='{.data.root-user}' | base64 -d; echo\n",
    "kubectl -n mlflow get secret sunrise-minio -o jsonpath='{.data.root-password}' | base64 -d; echo\n",
    "\n",
    "'''\n",
    "\n",
    "sunrise-minio                   Opaque               2      123d\n",
    "\n",
    "admin                            user\n",
    "\n",
    "ySO5ISk7Eq                       password\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44e91f0-59bc-4a8e-bbcf-5784ac64f56e",
   "metadata": {},
   "source": [
    "# 2. KServe\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a8dea189-4b61-472a-8d51-ba3a1d5f966c",
   "metadata": {},
   "source": [
    "eduardo@iquPC:training-pipeline$ # Show all containers & images in the KServe controller deployment\n",
    "kubectl -n kserve get deploy kserve-controller-manager \\\n",
    "  -o jsonpath='{range .spec.template.spec.containers[*]}{.name}{\" => \"}{.image}{\"\\n\"}{end}'\n",
    "\n",
    "# Print only the manager container image (this is your KServe version tag)\n",
    "kubectl -n kserve get deploy kserve-controller-manager \\\n",
    "  -o jsonpath='{.spec.template.spec.containers[?(@.name==\"manager\")].image}{\"\\n\"}'\n",
    "\n",
    "# Just the tag (strip repo/name):\n",
    "kubectl -n kserve get deploy kserve-controller-manager \\\n",
    "  -o jsonpath='{.spec.template.spec.containers[?(@.name==\"manager\")].image}' \\\n",
    "| sed -E 's#.*:([^:@]+)(@sha.*)?$#\\1#'\n",
    "kube-rbac-proxy => quay.io/brancz/kube-rbac-proxy:v0.18.0\n",
    "manager => kserve/kserve-controller:v0.15.0\n",
    "kserve/kserve-controller:v0.15.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a1ceca-d247-47d7-a51a-68bfdc968d32",
   "metadata": {},
   "source": [
    "### K server issue #1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ed5612-eed3-49e3-8de4-69fa05b7466c",
   "metadata": {},
   "source": [
    "Bingo — the ClusterRoleBindings point to the wrong namespace (kubeflow) for the kserve-controller-manager SA. That’s why every can-i came back no and the controller can’t sync caches.\n",
    "\n",
    "Let’s fix the bindings so they reference the SA in kserve.\n",
    "\n",
    "1) Recreate the two bindings with the correct subject\n",
    "\n",
    "(This is safer than JSON-patching indexes; it idempotently overwrites them.)\n",
    "\n",
    "\n",
    "**Manager -> needs cluster-wide perms**\n",
    "kubectl create clusterrolebinding kserve-manager-rolebinding \\\n",
    "  --clusterrole=kserve-manager-role \\\n",
    "  --serviceaccount=kserve:kserve-controller-manager \\\n",
    "  -o yaml --dry-run=client | kubectl apply -f -\n",
    "\n",
    "**Proxy -> used by kube-rbac-proxy sidecar**\n",
    "kubectl create clusterrolebinding kserve-proxy-rolebinding \\\n",
    "  --clusterrole=kserve-proxy-role \\\n",
    "  --serviceaccount=kserve:kserve-controller-manager \\\n",
    "  -o yaml --dry-run=client | kubectl apply -f -\n",
    "\n",
    "\n",
    "kubectl -n kserve rollout restart deploy/kserve-controller-manager\n",
    "kubectl -n kserve get pods -w\n",
    "\n",
    "**then:**\n",
    "kubectl -n kserve logs deploy/kserve-controller-manager -c manager --tail=200\n",
    "\n",
    "\n",
    "for r in \\\n",
    "  \"services\" \\\n",
    "  \"deployments.apps\" \\\n",
    "  \"virtualservices.networking.istio.io\" \\\n",
    "  \"httproutes.gateway.networking.k8s.io\" \\\n",
    "  \"inferenceservices.serving.kserve.io\" \\\n",
    "  \"trainedmodels.serving.kserve.io\" \\\n",
    "  \"inferencegraphs.serving.kserve.io\"\n",
    "do\n",
    "  printf \"%-45s \" \"$r\"; \\\n",
    "  kubectl auth can-i --as=system:serviceaccount:kserve:kserve-controller-manager list \"$r\" --all-namespaces\n",
    "done\n",
    "    \n",
    "######\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616ea53c-fc4e-4401-b457-e93084d5a21b",
   "metadata": {},
   "source": [
    "### #issue 2\n",
    "\n",
    "this check the problems if it is there becasue the user \"system:serviceaccount:kubeflow:kserve-controller-manager\" cannot get resource \"serviceaccounts\" in the namespace \"lstm-iqu\"\n",
    "* kubectl -n kubeflow logs deploy/kserve-controller-manager -c manager | grep -i credential^C\n",
    "* kubectl -n kubeflow get cm inferenceservice-config -o yaml | grep -A5 credentials\n",
    "\n",
    "note: Because the KServe controller can’t read your ServiceAccount in lstm-iqu, it fails to inject S3 env vars into the storage-initializer, so you get NoCredentialsError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16364d1-d2c8-437e-afe7-1dd23583b5d6",
   "metadata": {},
   "source": [
    "The kserver cannot inject the secrets credenatial and service account in the pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "690583f3-00bc-448b-9c08-d7f785f801f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cbca14-0f55-4fac-a227-3d513191263e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
