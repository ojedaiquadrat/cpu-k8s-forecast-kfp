{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b218cffa-d04b-4c8d-8660-75beb9817da4",
   "metadata": {},
   "source": [
    "# Kserver Model testing registartio. Read in the Kubeflow folder the info\n",
    "\n",
    "TEst-env TO be aligned with the seldom **kserve-mlserver such image is (seldonio/mlserver:1.5.0)** thsi should be run in the conda env mymlflow-env \n",
    "\n",
    "### USe the kserve deployment in the folder **inference-with-yaml-files** to test it\n",
    "**CODE to create the env**\n",
    "```\n",
    "conda create -n mymlflow-env python=3.10\n",
    "180  conda activate mymlflow-env\n",
    "181  conda install pytorch==2.2.1 cpuonly -c pytorch\n",
    "182  pip list\n",
    "183 pip install mlflow==2.10.2 mlserver==1.5.0 mlserver-mlflow==1.5.\n",
    "184  pip minio\n",
    "185  pip install minio\n",
    "python -m ipykernel install --user --name=mymflow-env --display-name=\"Python (mymlfow-env)\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "579415da-e5f9-4721-be4e-381cadefba85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: s3://k8s-resources-forecast/data/k8s-preprocessed/node-1-X_train/X_train.npy shape=(8238, 5, 1)\n",
      "Downloaded: s3://k8s-resources-forecast/data/k8s-preprocessed/node-1-y_train/y_train.npy shape=(8238, 1, 1)\n",
      "Downloaded: s3://k8s-resources-forecast/data/k8s-preprocessed/node-1-X_test/X_test.npy shape=(2060, 5, 1)\n",
      "Downloaded: s3://k8s-resources-forecast/data/k8s-preprocessed/node-1-y_test/y_test.npy shape=(2060, 1, 1)\n",
      "X_train shape: (8238, 5, 1) y_train shape: (8238, 1, 1)\n",
      "X_val shape: (2060, 5, 1) y_val shape: (2060, 1, 1)\n",
      "Epoch 1/35 | Train Loss: 0.01594 | Val Loss: 0.00086\n",
      "Epoch 2/35 | Train Loss: 0.00552 | Val Loss: 0.00062\n",
      "Epoch 3/35 | Train Loss: 0.00518 | Val Loss: 0.00059\n",
      "Epoch 4/35 | Train Loss: 0.00493 | Val Loss: 0.00078\n",
      "Epoch 5/35 | Train Loss: 0.00472 | Val Loss: 0.00082\n",
      "Epoch 6/35 | Train Loss: 0.00438 | Val Loss: 0.00062\n",
      "Epoch 7/35 | Train Loss: 0.00415 | Val Loss: 0.00069\n",
      "Epoch 8/35 | Train Loss: 0.00414 | Val Loss: 0.00068\n",
      "Early stopping triggered!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/12 04:39:13 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/12 04:39:16 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model + artifacts logged in MLflow (with input_example and signature).\n",
      "üèÉ View run 2025-09-12-04:38:49-cpu-node-1-forecast at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27/runs/81db34d9845c43bcade8d3f065e50241\n",
      "üß™ View experiment at: http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080/#/experiments/27\n",
      "Final MAE: 0.0205 | RMSE: 0.0260 | R2: 0.7087\n"
     ]
    }
   ],
   "source": [
    "# 1. Imports & MinIO client creation adn Download Function\n",
    "\n",
    "import numpy as np\n",
    "import io\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from minio import Minio\n",
    "import datetime\n",
    "\n",
    "tracking_timestamp =  datetime.datetime.now().strftime(\"%Y-%m-%d-%H:%M:%S-\")\n",
    "\n",
    "# Function to download numpy arrays from MinIO\n",
    "def download_numpy_from_minio(minio_client, bucket, object_name):\n",
    "    try:\n",
    "        with minio_client.get_object(bucket, object_name) as response:\n",
    "            arr = np.load(io.BytesIO(response.read()))\n",
    "            print(f\"Downloaded: s3://{bucket}/{object_name} shape={arr.shape}\")\n",
    "            return arr\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "# Minio client\n",
    "minio_client = Minio(\n",
    "    \"minio-service.kubeflow.svc.cluster.local:9000\",\n",
    "    access_key=\"minio\",\n",
    "    secret_key=\"minio123\",\n",
    "    secure=False,\n",
    ")\n",
    "# SET MLflow URI in the k8s cluster\n",
    "# This line must be placed before any mlflow.start_run()\n",
    "mlflow.set_tracking_uri(\"http://sunrise-mlflow-tracking.mlflow.svc.cluster.local:5080\")\n",
    "mlflow.set_experiment(\"k8s-cpu-forecasting\")\n",
    "\n",
    "\n",
    "# 2: Load Train/Val Sets From MinIO\n",
    "bucket_name = \"k8s-resources-forecast\"\n",
    "object_names = {\n",
    "    \"X_train\": \"data/k8s-preprocessed/node-1-X_train/X_train.npy\",\n",
    "    \"y_train\": \"data/k8s-preprocessed/node-1-y_train/y_train.npy\",\n",
    "    \"X_val\":   \"data/k8s-preprocessed/node-1-X_test/X_test.npy\",\n",
    "    \"y_val\":   \"data/k8s-preprocessed/node-1-y_test/y_test.npy\",\n",
    "}\n",
    "\n",
    "X_train = download_numpy_from_minio(minio_client, bucket_name, object_names[\"X_train\"])\n",
    "y_train = download_numpy_from_minio(minio_client, bucket_name, object_names[\"y_train\"])\n",
    "X_val   = download_numpy_from_minio(minio_client, bucket_name, object_names[\"X_val\"])\n",
    "y_val   = download_numpy_from_minio(minio_client, bucket_name, object_names[\"y_val\"])\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape, \"y_val shape:\", y_val.shape)\n",
    "\n",
    "\n",
    "## 3: Build PyTorch DataLoaders\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n",
    "                              torch.tensor(y_train, dtype=torch.float32))\n",
    "val_dataset   = TensorDataset(torch.tensor(X_val,   dtype=torch.float32),\n",
    "                              torch.tensor(y_val,   dtype=torch.float32))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "# 4: Define LSTM Model\n",
    "class LSTMForecaster(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, output_size=1, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out.unsqueeze(1)  # (batch, horizon, 1)\n",
    "\n",
    "# 5: Training Loop With Early Stopping and MLflow Logging\n",
    "\n",
    "def train_model_with_early_stopping(\n",
    "    train_loader, val_loader, input_size=1, hidden_size=64, num_layers=2,\n",
    "    lr=0.001, epochs=35, patience=5, dropout=0.0, model_name=\"node-1-cpu-pct-forecast\", run_name=None\n",
    "):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = LSTMForecaster(input_size, hidden_size, num_layers, output_size=1, dropout=dropout).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    wait = 0\n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        mlflow.log_params({\n",
    "            \"input_size\": input_size, \"hidden_size\": hidden_size,\n",
    "            \"num_layers\": num_layers, \"lr\": lr, \"epochs\": epochs,\n",
    "            \"batch_size\": BATCH_SIZE, \"dropout\": dropout, \"patience\": patience\n",
    "        })\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            running_loss = 0\n",
    "            for xb, yb in train_loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                out = model(xb)\n",
    "                loss = criterion(out, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "            train_loss = running_loss / len(train_loader)\n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            model.eval()\n",
    "            val_running_loss = 0\n",
    "            all_pred, all_true = [], []\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in val_loader:\n",
    "                    xb, yb = xb.to(device), yb.to(device)\n",
    "                    out = model(xb)\n",
    "                    loss = criterion(out, yb)\n",
    "                    val_running_loss += loss.item()\n",
    "                    all_pred.append(out.cpu().numpy())\n",
    "                    all_true.append(yb.cpu().numpy())\n",
    "            val_loss = val_running_loss / len(val_loader)\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.5f} | Val Loss: {val_loss:.5f}\")\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model = model.state_dict()\n",
    "                wait = 0\n",
    "            else:\n",
    "                wait += 1\n",
    "                if wait >= patience:\n",
    "                    mlflow.log_metric(\"epoch_actual\", epoch + 1)  # real epoch that run\n",
    "                    print(\"Early stopping triggered!\")\n",
    "                    break\n",
    "\n",
    "        # Load best\n",
    "        if best_model: model.load_state_dict(best_model)\n",
    "\n",
    "        # Final metrics\n",
    "        model.eval()\n",
    "        preds, targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                out = model(xb.to(device)).cpu().numpy()\n",
    "                preds.append(out)\n",
    "                targets.append(yb.cpu().numpy())\n",
    "        preds = np.concatenate(preds).reshape(-1)\n",
    "        targets = np.concatenate(targets).reshape(-1)\n",
    "\n",
    "        mae  = mean_absolute_error(targets, preds)\n",
    "        #rmse = mean_squared_error(targets, preds, squared=False) #  scikit-learn new version has this\n",
    "        rmse = np.sqrt(mean_squared_error(targets, preds))\n",
    "        r2   = r2_score(targets, preds)\n",
    "        mlflow.log_metric(\"val_mae\", mae)\n",
    "        mlflow.log_metric(\"val_rmse\", rmse)\n",
    "        mlflow.log_metric(\"val_r2\", r2)\n",
    "\n",
    "        # --- Plots\n",
    "        plt.figure(figsize=(10,4))\n",
    "        plt.plot(targets, label=\"True\")\n",
    "        plt.plot(preds, label=\"Predicted\")\n",
    "        plt.legend(); plt.title(\"True vs. Predicted CPU% (Validation)\")\n",
    "        #most KFP v2 components, the working directory for your step is /tmp, which is writeable.\n",
    "        plt.tight_layout(); plt.savefig(\"/tmp/true_vs_pred.png\"); plt.close()\n",
    "        mlflow.log_artifact(\"/tmp/true_vs_pred.png\")\n",
    "\n",
    "        plt.figure(figsize=(10,4))\n",
    "        plt.plot(preds - targets)\n",
    "        plt.title(\"Residuals Over Time\"); plt.xlabel(\"Time\"); plt.ylabel(\"Residual (Pred - True)\")\n",
    "        #most KFP v2 components, the working directory for your step is /tmp, which is writeable.\n",
    "        plt.tight_layout(); plt.savefig(\"/tmp/residuals.png\"); plt.close()\n",
    "        mlflow.log_artifact(\"/tmp/residuals.png\")\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(train_losses, label=\"Train Loss\")\n",
    "        plt.plot(val_losses, label=\"Val Loss\")\n",
    "        plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(\"Learning Curve\")\n",
    "        #most KFP v2 components, the working directory for your step is /tmp, which is writeable.\n",
    "        plt.legend(); plt.tight_layout(); plt.savefig(\"/tmp/learning_curve.png\"); plt.close()\n",
    "        mlflow.log_artifact(\"/tmp/learning_curve.png\")\n",
    "\n",
    "        # --- (NEW) Infer signature and log model properly ---\n",
    "        sample_input_t = torch.tensor(X_val[:1], dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            sample_output_np = model(sample_input_t).detach().cpu().numpy()\n",
    "        input_example_np = sample_input_t.cpu().numpy()\n",
    "        \n",
    "        from mlflow.models import infer_signature\n",
    "        signature = infer_signature(input_example_np, sample_output_np)\n",
    "        \n",
    "        mlflow.pytorch.log_model(\n",
    "            model,\n",
    "            artifact_path=\"model\",\n",
    "            input_example=input_example_np,\n",
    "            signature=signature,\n",
    "        )\n",
    "        print(\"Model + artifacts logged in MLflow (with input_example and signature).\")\n",
    "       \n",
    "\n",
    "    return model, (mae, rmse, r2)\n",
    "\n",
    "# 6: Run the Training & Logging\n",
    "EPOCHS = 35\n",
    "PATIENCE = 5\n",
    "#tracking_timestamp =  datetime.datetime.now().strftime(\"%Y-%m-%d-%H:%M:%S-\") \n",
    "model, metrics = train_model_with_early_stopping(\n",
    "    train_loader, val_loader,\n",
    "    input_size=X_train.shape[-1],\n",
    "    hidden_size=64,\n",
    "    num_layers=2,\n",
    "    lr=0.001,\n",
    "    epochs=EPOCHS,\n",
    "    patience=PATIENCE,\n",
    "    dropout=0.1,\n",
    "    model_name= tracking_timestamp + \"cpu-node-1-pct-model\",\n",
    "    run_name= tracking_timestamp + \"cpu-node-1-forecast\" \n",
    ")\n",
    "\n",
    "print(f\"Final MAE: {metrics[0]:.4f} | RMSE: {metrics[1]:.4f} | R2: {metrics[2]:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5069b258-e5fc-4859-ad7f-9d72758a8ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import io\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from minio import Minio\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e961ac88-03b0-4ab2-a41c-53b3ac888ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cpu\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49661b9d-155c-4a1a-ac69-26492228f94f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mymlfow-env)",
   "language": "python",
   "name": "mymflow-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
